[{"content":"TLDR: I built a semantic movie search app with GPT-4. You can check it out here: https://moviesgpt.net/. And here\u0026rsquo;s the Github repo: https://github.com/sinzin91/moviesGPT\nthe hero keeps forgetting who he is\nIdea I\u0026rsquo;ve been thinking a lot about potential products that one can build around LLMs. One idea I mentioned jokingly to some friends was to use GPT as a natural language interface to a movies API.\nIn theory, I thought, you could ask GPT about movies semantically, meaning you could search based on what the movie is about or its content, instead of just raw keyword search. For example, I could search for \u0026ldquo;movies where all the main characters die\u0026rdquo; and get back \u0026ldquo;The Departed\u0026rdquo;. Then I could use the response to query a movies API like The Movies Database. Google is surprisingly bad at this, returning links to listicles instead of the movies themselves.\nThe current way to do this, and the one that even ChatGPT recommends, is to gather data on all the movies, generate word embeddings on that data, store it in a Vector database, and then query using something like cosine similarity. But GPT-3, having been trained on all internet data, has \u0026ldquo;seen\u0026rdquo; every movie and discussion around every movie already. It already has the embeddings. And it already \u0026ldquo;knows\u0026rdquo; how to find those movies given the right prompt.\nImplementation With this rough sketch of an idea, I sipped some coffee and entered this into GPT-4:\nYou are a master professional front end React developer. Show how you would build a front end that includes a search bar at the top. Below the search bar are six cards which include the movie cover with the title below it. Searches hit The Movie Database api\u0026#39;s search endpoint with the search term. The results from the API call are used to update the cards below the search bar. The site uses a black and blue, dark mode style theme, with minimal UI components. I basically just wrote that off the cuff with no large amount of premeditation, and got back a very reasonable starting place for my app: Note: I am a hobbyist front-end engineer at best and only know enough React and Javascript to be slightly dangerous. I absolutely hate CSS, and can\u0026rsquo;t remember the difference between align-items and justify-content to save my life.\nTo my surprise, I was able to just copy paste the code from GPT-4 to get a decent looking site!\nI then asked to change it so that it calls OpenAI first:\nOk great! Now I want you to change it so that searches are sent to OpenAI\u0026#39;s text-davinci-003 API. Hit The Movies Database API with each element from the returned array, and render those movies in the MovieGrid. Interestingly, GPT generated a prompt from my prompt:\nconst response = await openai.Completion.create( { engine: \u0026#34;text-davinci-003\u0026#34;, prompt: `Find 6 movie titles related to \u0026#34;${searchTerm}\u0026#34;` }) This prompt is not precise enough though, so here I actually had to do some work:\nReturn an array of movie titles that best match this search term, ordered from most to least relevant. Generate up to 16 titles. If you are unable to answer the question, start your response with Sorry. Example: prompt: \u0026#34;movies with brando\u0026#34; response: [\u0026#34;The Godfather\u0026#34;, \u0026#34;The Godfather: Part II\u0026#34;, \u0026#34;Apocalypse Now\u0026#34;, \u0026#34;The Wild One\u0026#34;] prompt: ${searchTerm} response: I\u0026rsquo;m giving GPT an example of the kind of response I expect. In this case, I want it to create a valid array of movie titles.\nWith this change, I had the first working POC of my original idea! The last time experienced such a sensation of god-like empowerment might have been unlocking robots in Factorio.\nin Factorio, eventually you can have robots automatically build things based on blueprints\nWhew, okay, great. Now what?\nI showed the app to a friend, and he mentioned that it looked terrible on mobile. So I asked GPT-4 to \u0026ldquo;change the CSS so the website works well on mobile phones.\u0026rdquo; Lo and behold, after copying over the CSS directly, the site worked flawlessly on mobile. No futzing with media queries for me!\nI also realized that I wanted to add star ratings to these movies to get a sense of their popularity. The TMDb API returns \u0026ldquo;vote_ratings,\u0026rdquo; which is a number from 0 to 10. I found the distribution of \u0026ldquo;vote_ratings\u0026rdquo; here: https://www.kaggle.com/code/erikbruin/movie-recommendation-systems-for-tmdb.\nAdding a stars component was also mostly copy/paste once I wrote the prompt:\nThe movie database api returns a `vote_average` in the response. I want a \u0026#34;Stars\u0026#34; component below each movie title that gives gives the movie 1 star if `vote_average` is between 0 to 2, 2 stars if it is between 2 to 4, etc. If a movie got one star, there should be a single bright yellow star and four grey stars in the component. I also wanted something to happen when I clicked on the cards. Maybe show the movie summary, release date, etc. Here\u0026rsquo;s the prompt: One thing that was bothering me in terms of practical usability was the lack of Rotten Tomatoes ratings. Often, that\u0026rsquo;s the first thing I check when deciding whether to watch a given movie. Unfortunately, Rotten Tomatoes charges $60k/year (!!) for access to their API. Then I had the idea of asking GPT for the Rotten Tomatoes ratings. To my surprise, it does seem to have a sense for the ratings. Although they are not fully accurate, they seem to be generally in the right ballpark.\nI updated my prompt to generate a new data structure that includes the Rotten Tomatoes ratings:\nReturn a JSON object movie titles that best match this search term and their Rotten Tomatoes tomatometer score, ordered from most to least relevant. Get the most up to date and accurate Rotten Tomatoes tomatometer score. Generate up to 12 titles. If you are unable to answer the question, return a string that starts with Sorry. The response must be a valid JSON. Example: prompt: \u0026#34;movies with brando\u0026#34; response: [ { \u0026#34;title\u0026#34;: \u0026#34;The Godfather\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 98 }, { \u0026#34;title\u0026#34;: \u0026#34;The Godfather: Part II\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 97 }, { \u0026#34;title\u0026#34;: \u0026#34;Apocalypse Now\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 96 }, { \u0026#34;title\u0026#34;: \u0026#34;The Wild One\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 85 } ] prompt: ${searchTerm} response: I also had GPT make me the new Rotten Tomatoes rating component:\nNow I can safely avoid these movies!\nI was surprised by how well semantic search works out of the box with GPT. However, there are some limitations. One is that it only recognizes movies up to the date it was trained, which was late 2021. When asked about movies released after that, it simply responds that it doesn\u0026rsquo;t know. This issue may be addressed by the Plugins that OpenAI announced, which would allow GPT to call live APIs to fetch real-time data. One could also probably create a fine-tuned model that is trained on more recent movies.\ncan\u0026rsquo;t find movies from 2022\nI tried using gpt-3.5-turbo, but that model seemed to be much more prudish, refusing to respond to searches on movies deemed unseemly by the RLHF moderators. So I switched back to text-davinci-003 for now.\nLimitations To be clear, I still had to do some coding to get the functionality and styling to match exactly what I wanted. I don\u0026rsquo;t think someone without experience in React or Javascript would be able to replicate this. GPT still gets some things wrong, like telling me to use outdated libraries or generating wonky styles (who wants a blue background on a header??). But it\u0026rsquo;s getting pretty close.\nIn more ambitious projects, I\u0026rsquo;ve noticed that GPT starts to \u0026ldquo;forget\u0026rdquo; the code it had previously suggested. So when I ask to change some function, it spits out a new version of the file that has a completely different implementation and method names. Maybe this is a result of the limited context window. I\u0026rsquo;ve gotten around this by pasting in the code again and asking it to make the change given that context.\nClosing Thoughts I got the feeling that I was a tech lead pair programming with a very knowledgeable junior engineer. It doesn\u0026rsquo;t do well with big picture decisions, but knows how to implement very well given the right direction. To be fair, I\u0026rsquo;m not doing anything groundbreaking here. There must be tons of sites like this in the pretraining data, so it\u0026rsquo;s relatively easy for GPT to generate the relevant code.\nIt was also much easier to get into that elusive flow state while hacking this out. The dopamine hits from thinking of a feature and seeing it in action just kept coming, without the usual frustrations of not knowing how a particular function works and having to look it up. This makes coding fun again.\nIt\u0026rsquo;s clear that I am the bottleneck in this process. I\u0026rsquo;m sitting here copying and pasting from GPT with some slight modifications. It seems like the natural progression here is to have GPT directly create the code based on my prompts. I imagine you could build a more advanced \u0026ldquo;Create React App\u0026rdquo; that generates and updates the app based on your prompts.\nI hope this inspires people to pursue building those apps they always wanted to build, but couldn\u0026rsquo;t find time for. GPT still does not know what app to build and why it should build it, which is where we come in. Let a thousand flowers bloom!\n","permalink":"https://tenzinwangdhen.com/posts/semantic-movie-search-with-gpt/","summary":"TLDR: I built a semantic movie search app with GPT-4. You can check it out here: https://moviesgpt.net/. And here\u0026rsquo;s the Github repo: https://github.com/sinzin91/moviesGPT\nthe hero keeps forgetting who he is\nIdea I\u0026rsquo;ve been thinking a lot about potential products that one can build around LLMs. One idea I mentioned jokingly to some friends was to use GPT as a natural language interface to a movies API.\nIn theory, I thought, you could ask GPT about movies semantically, meaning you could search based on what the movie is about or its content, instead of just raw keyword search.","title":"GPT-4 made me a GPT powered movie search app"},{"content":"TLDR \u0026ldquo;Peak: Secrets from the New Science of Expertise\u0026rdquo; by Anders Ericsson challenges conventional wisdom about talent, skill acquisition, and what it takes to achieve true expertise. Ericsson, a psychologist and researcher in the field of expertise, highlights several experiments to back up his claims, although some of the cited studies had small sample sizes. Despite containing some contradictions, the book offers a fascinating exploration of the science of expertise and empowers readers to pursue their path to mastery. Ericsson demonstrates that deliberate practice, not innate talent, is the key to mastery.\nDeliberate Practice Deliberate practice, a term coined by Ericsson, refers to a focused and intentional approach to skill development. It involves consistently working on specific areas of weakness or challenge, rather than merely repeating tasks or engaging in casual practice. To achieve this, it is necessary to set clear goals, seek feedback, and engage in continuous self-assessment to refine techniques and mental representations. Deliberate practice is designed to push individuals beyond their comfort zones, leading to significant improvements in performance and the eventual attainment of expertise in a given domain.\nEricsson\u0026rsquo;s concept of deliberate practice challenges the popular notion of Malcolm Gladwell\u0026rsquo;s \u0026ldquo;10,000-hour rule.\u0026rdquo; Merely spending time on a task does not guarantee expertise. It is essential to identify areas of weakness and actively work to improve them. For example, London cab drivers have developed larger hippocampi than bus drivers due to the former having to pass an extremely difficult exam and navigate to any location in London without a map.\nEricsson details an experiment in which a subject named Steve was trained to recall up to 86 numbers in a row after two years of deliberate practice. This was a significant improvement over the standard wisdom at the time, which held that working memory can only store 7 pieces of information, plus or minus two. Steve\u0026rsquo;s success can be attributed to his background as a runner, which made him accustomed to self-development and more likely to persevere through plateaus. Effective mnemonics were key to Steve\u0026rsquo;s progress, allowing him to surpass the typical working memory limit of seven numbers. Joshua Foer\u0026rsquo;s book \u0026ldquo;Moonwalking with Einstein\u0026rdquo; got me interested in mnemonic techniques, and it is interesting to note that he consulted with Ericsson.\nNeuroscience of practice Both the brain and body adjust to maintain homeostasis, a tendency towards equilibrium. For example, during endurance training, your body will eventually build additional capillaries to increase blood flow. Similarly, with the brain, neurons that \u0026ldquo;fire together, wire together\u0026rdquo;. Practicing just beyond your comfort zone signals to your brain that it needs to change to maintain homeostasis. Simple repetition does not have this effect.\nInterestingly, Ericsson relates an experiment that showed London cabbies who passed the test and started working were less effective at general recall than the control group. This might be because the adult brain does not experience as much neurogenesis, so the process of skill acquisition involves pruning inefficient synapses to be more efficient for certain tasks. This finding might have implications for what we choose to prioritize practicing.\nEricsson also mentions skilled \u0026ldquo;three-finger\u0026rdquo; braille readers who use each of their fingers for specific parts of the task. Brain scans showed that the parts of the brain that control these fingers become enlarged to the point where they overlap. These readers develop extreme sensitivity in their fingers but can\u0026rsquo;t tell which finger is being touched. The idea that the brain is not static, but can change and adapt with directed practice, is inspiring and motivating.\nThe Innate Talent Myth Ericsson challenges the belief in innate talent by first examining the concept of \u0026ldquo;perfect pitch,\u0026rdquo; the ability to identify any note in music, which was once considered a natural gift. Ericsson cites Mozart as an example of a prodigy who possessed this ability from a young age. However, the author argues that with just a year of training a few minutes a day, almost any child can learn to develop perfect pitch, provided they begin before the age of six. Even adults are able to learn this skill, although it takes longer and more deliberate practice.\nLater in the book, Ericsson debunks the notion of the savant, who may excel in a narrow field but has limited ability in other areas. He uses the example of \u0026ldquo;Donnie,\u0026rdquo; who could identify the day of the week for any date, to illustrate his point. Ericsson shows that savants often become fixated on their interests, leading to deliberate practice and mastery in a very specific domain. Outsiders only see the results of their intense focus and dedication.\nMental Representations Ericsson\u0026rsquo;s thesis focuses on the idea that deliberate practice requires the development of efficient mental representations. This concept is similar to the idea of \u0026ldquo;mental models\u0026rdquo; popularized by Charlie Munger. Ericsson uses the example of chess players who use \u0026ldquo;chunking\u0026rdquo; to recognize patterns on the board to illustrate this idea. Through deliberate practice, masters stop seeing individual pieces and instead recognize groups of pieces forming a semantic unit.\nChess players are often portrayed in popular culture as hyper intelligent, but Ericsson mentions studies that showed that adult chess players do not have a higher IQ than average. While children with high IQs may learn the rules faster, ultimately it comes down to who practices the most. Interestingly, Ericsson notes that Go players, on average, have a lower IQ than average, despite the fact that computers have yet to beat the world\u0026rsquo;s best Go players. This was published in 2015, and since then, AlphaGo famously beat the Go world champion.\nIn several sports anecdotes, Ericsson shows that athletes can surpass their predecessors by adopting better practice techniques, which are essentially better mental representations. He emphasizes the importance of learning from experts and adopting their practice methods to improve more rapidly.\nContradictions Despite its persuasive arguments, \u0026ldquo;Peak\u0026rdquo; is not without contradictions. For instance, Ericsson claims in one section that deliberate practice is not enjoyable for practitioners, while in another he says that it is. He asserts that deliberate practice can lead to virtually any accomplishment, yet also acknowledges that certain abilities can only be developed during childhood or for those with certain genetic attributes.\nEricsson notes that younger doctors are often more effective than those with 20 years of experience because their medical school knowledge is more recent. However, he also emphasizes that mere knowledge is not enough and that one needs to acquire skills through practice. While Ericsson tried to address both sides of the argument, it would have been helpful if he were more explicit about the contradictions in his thesis.\nApplication To make the idea of deliberate practice more concrete, let\u0026rsquo;s use the example of practicing guitar every day. A naive way to practice would be to mindlessly play through the same songs repeatedly each day, failing at the same sections each time. This mindless repetition can leave you stagnating in a well-worn rut, making you feel like you\u0026rsquo;ve reached the peak of your abilities. I\u0026rsquo;ll admit, this is often how I practice guitar.\nThe deliberate practice approach, on the other hand, is to focus on the difficult portions of the songs and practice those parts intensively. Once you have mastered the songs, you move on to more challenging pieces that are just outside of your comfort zone. It helps to measure your progress and note exactly which parts are giving you issues. You can also seek out other practitioners who can provide you with better and more efficient practice techniques. Though this new approach might be less fun, it is the way to mastery (assuming that\u0026rsquo;s your goal!)\nClosing \u0026ldquo;Peak\u0026rdquo; is a captivating and insightful examination of the science of expertise. Personally, I have started exploring how I can incorporate deliberate practice into my daily habits like meditation and guitar. By uncovering the secrets of deliberate practice, Anders Ericsson has provided readers with the opportunity to pursue their own path towards mastery, regardless of their background or perceived \u0026ldquo;talent.”\n","permalink":"https://tenzinwangdhen.com/posts/book-review-peak/","summary":"TLDR \u0026ldquo;Peak: Secrets from the New Science of Expertise\u0026rdquo; by Anders Ericsson challenges conventional wisdom about talent, skill acquisition, and what it takes to achieve true expertise. Ericsson, a psychologist and researcher in the field of expertise, highlights several experiments to back up his claims, although some of the cited studies had small sample sizes. Despite containing some contradictions, the book offers a fascinating exploration of the science of expertise and empowers readers to pursue their path to mastery.","title":"Book Review - Peak: Secrets from the New Science of Expertise"},{"content":"TLDR I created SocratesGPT to test the concept of using AI to generate questions about a given topic. Its goal you learn topics better by asking you questions about it. I also provide some technical details on the implementation.\nWhy? Over a year ago, I began using Anki, a spaced repetition flashcard app that helps me retain information over the long term by taking advantage of the Ebbinghaus forgetting curve. Memory is like a leaky bucket, and it was incredibly frustrating to realize I\u0026rsquo;d forgotten most of what I learned. Anki has enabled me to confidently tackle difficult technical topics that I would have otherwise avoided.\nOne issue with Anki is that you can start to \u0026ldquo;overfit\u0026rdquo; on the questions you wrote. With Anki, you look at the card and then check the answer after trying to recall it. Once you\u0026rsquo;ve seen the answer, you rate how easily you were able to recall it, which determines when the question will reappear in your deck. Creating questions can be time consuming, so I\u0026rsquo;ve found that most of my cards end up being \u0026ldquo;cloze deletions\u0026rdquo;, i.e. fill-in-the-blank. This increases the risk of memorizing the answer to the card rather than truly understanding the concept.\nWhat if we could use AI to help us understand a topic better?\nSocratesGPT Unless you\u0026rsquo;ve been living under a particularly forlorn boulder, you\u0026rsquo;ve heard about ChatGPT. You may not know that you can access GPT-3.5 as an API. The most advanced model available via OpenAI\u0026rsquo;s API is gpt-3.5-turbo. This space is moving fast. When I started this project, the most advanced model was text-davinci-003 which was 10x more expensive and somewhat slower. Edit: now GPT-4 is out.\nGPT (generative pre-trained transformer) is a type of \u0026ldquo;large language model\u0026rdquo; (LLM) (sorry about the acronyms). By using \u0026ldquo;prompt engineering\u0026rdquo;, you can have the model return a structured JSON output for a given prompt, which can then be rendered in a UI. This means the app\u0026rsquo;s \u0026ldquo;backend\u0026rdquo; can consist of a single prompt.\nI saw a great example of this at https://github.com/varunshenoy/GraphGPT. It shows an example of using one-shot prompting to teach GPT to give a JSON structured response. I was surprised to find that this style of prompting always gives back valid JSON, assuming you also set the model parameters appropriately.\nI created SocratesGPT to test the concept of using AI to generate questions about a given text. The Socratic method is a questioning style that encourages students to discover their beliefs and uncover hidden assumptions. However, SocratesGPT does not fully follow the Socratic style, as there is no real dialogue between student and teacher. The name is more aspirational than descriptive.\nIn my prompt, I ask the model to impersonate Socrates, and generate questions based on the given text. I also provide an example of the expected response in JSON format. The React front end parses the JSON and renders it. If you ask for another question, the app updates the prompt with the previous state of questions and options selected and pass it back to the model.\nCreating a traditional backend to power an app like this without the use of LLMs would be highly non-trivial.\n\u0026ldquo;Prompt Engineering\u0026rdquo; Prompt engineering is the process of designing effective prompts for large language models such as GPT. Effective prompts are more likely to elicit high-quality outputs. Garbage prompt in, garbage response from the LLM.\nI started with a fairly simple prompt:\nYou are impersonating a question generator using the socratic method. You will be given a prompt, and you must respond with a question about that prompt. The response must be a valid json object with the following fields: prompt, question, answer, and correct. Eventually I had to add the following lines to get a cleaner response:\nYou cannot ask the same question twice. Try to limit the number of words in the choices to 4. If a choice is selected, it should be marked as selected: true. If a choice is not selected, it should be marked as selected: false. I had the feeling of training an overly eager genie when phrasing my prompt. When you ask a genie to stop the trolley from hitting the pedestrian, the genie might find blowing up the trolley to be a perfectly reasonable solution. So you end up adding additional clauses: \u0026ldquo;err, also don\u0026rsquo;t blow it up!\u0026rdquo;.\nThis is followed by a one-shot training example, where I provide a single example of what I want the model to do. I provide a starting state with my initial data structure:\nExamples: current state: { \u0026#34;counter\u0026#34;: 1, \u0026#34;prompt\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;questions\u0026#34;: [{}] } prompt is the text the model should generate questions on. questions is an array of question objects.\nThen I show an example prompt, and the expected response from the model:\nprompt: The sky is blue. new state: { \u0026#34;counter\u0026#34;: 1, \u0026#34;prompt\u0026#34;: \u0026#34;The sky is blue.\u0026#34;, \u0026#34;questions\u0026#34;: [{ \u0026#34;question\u0026#34;: \u0026#34;What color is the sky?\u0026#34;, \u0026#34;choices\u0026#34;: [{ \u0026#34;text\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;correct\u0026#34;: true, \u0026#34;selected\u0026#34;: false }, { \u0026#34;text\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;correct\u0026#34;: false, \u0026#34;selected\u0026#34;: false }, { \u0026#34;text\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;correct\u0026#34;: false, \u0026#34;selected\u0026#34;: false }, { \u0026#34;text\u0026#34;: \u0026#34;yellow\u0026#34;, \u0026#34;correct\u0026#34;: false, \u0026#34;selected\u0026#34;: false }] }] } Each question includes the generated question, along with an array of choices. The selected boolean is used in the front end to maintain the state of which options the user clicked, so these aren\u0026rsquo;t lost when a new prompt is generated.\nFinally we create a way for us to dynamically update the prompt:\ncurrent state: $state prompt: $prompt new state: In the front end, we inject the current state into $state and the prompt into $prompt:\nfetch(\u0026#34;prompts/data.prompt\u0026#34;) .then((response) =\u0026gt; response.text()) .then((text) =\u0026gt; text.replace(\u0026#34;$prompt\u0026#34;, prompt)) .then((text) =\u0026gt; text.replace(\u0026#34;$state\u0026#34;, JSON.stringify(state))) We have some control over the parameters of the model, such as the temperature, max tokens, and top p. I found that the model works best when the temperature is set to 0.3. Temperature controls the \u0026ldquo;creativity\u0026rdquo; of the model. A lower temperature means the model is more likely to generate correct, almost deterministic responses. A higher temperature means the model generally leads to creative responses. frequency_penalty sets a penalty for repeating words. presence_penalty sets a penalty for repeating n-grams. top_p sets the probability mass function cutoff.\nconst DEFAULT_PARAMS = { model: \u0026#34;gpt-3.5-turbo\u0026#34;, temperature: 0.3, max_tokens: 800, top_p: 1, frequency_penalty: 0, presence_penalty: 0, }; After the user clicks \u0026ldquo;Generate Question\u0026rdquo;, the value of $prompt is obtained from the prompt text area in the UI. The $state starts as a skeleton of the data structure provided in the training example. We call OpenAI\u0026rsquo;s new gpt-3.5-turbo chat completions API with data.prompt. The JSON response contained in data.choices[0].message.content is parsed to update the state and render the question in the UI.\nI found that the prompt in the new API needs to use single quotes instead of quotes when sent to the model, and then I have to replace the single quotes in the response with double quotes again to make it valid JSON. There\u0026rsquo;s probably a cleaner way to do this. I also feed the entire prompt as the role user, but some parts of it may be better suited to the system role.\nconst params = { ...DEFAULT_PARAMS, messages: [{ role: \u0026#34;user\u0026#34;, content: prompt }], }; ... const requestOptions = { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, Authorization: \u0026#34;Bearer \u0026#34; + String(apiKey || OPENAI_API_KEY), }, body: JSON.stringify(params), }; fetch(\u0026#34;https://api.openai.com/v1/chat/completions\u0026#34;, requestOptions) .then((response) =\u0026gt; response.json()) .then((data) =\u0026gt; { const text = data.choices[0].message.content; // replace \u0026#39; with \u0026#34; to make it valid JSON const new_state = JSON.parse(text.replace(/\u0026#39;/g, \u0026#39;\u0026#34;\u0026#39;)); setState(new_state); If the user generates another question, we pass in the $state which now includes the first question. This lets the model we know what it already asked.\nLimitations There are several limitations with the current implementation:\nWhen providing very short input text, the model may generate questions that are not grounded in the text. For example, if the input text is \u0026ldquo;The sky is blue\u0026rdquo;, the model may generate a question like \u0026ldquo;Why is the sky blue?\u0026rdquo; even though the reason is not provided in the text. This is related to the \u0026ldquo;grounding problem\u0026rdquo;, which is one of the major flaws of LLMs. Shorter input text provides less grounding, thus allowing for more hallucinations. Occasionally, the model seems to \u0026ldquo;undo\u0026rdquo; changes in state. For example, a question might get removed from state on the next run. It can take up to 20 seconds to receive a response from the API. The response time seems to increase with the size of the prompt. This can make it less engaging. Newer versions of the OpenAI API will likely have faster response times. Setting frequency_penalty and presense_penalty parameters to 1 seems to result in invalid JSON. This might be because they make the model less likely to generate characters like { multiple times, which is required for the JSON to be valid. Future There\u0026rsquo;s a few ways SocratesGPT could be improved. Users could be able to save questions, and later be quizzed on them using spaced repetition. Larger context windows would allow the model to create questions on entire books. Eventually, GPT could be \u0026ldquo;fine-tuned\u0026rdquo; to ask more effective questions. You might even be able to implement reinforcement learning from human feedback (RLHF). Students could rate the quality of questions, which is then fed back into the model.\nAs multi-modal models mature, the AI could even generate diagrams, such as an image of a section of the brain with an arrow pointing to the area that the user is asked to label. Finally, the grounding problem should be addressed to prevent the model from \u0026ldquo;hallucinating\u0026rdquo; questions that are not in the input text.\nThe \u0026ldquo;T\u0026rdquo; in GPT stands for transformer, which is currently the most powerful deep learning architecture for several tasks, including NLP. There will likely be better architectures in the future. As the cost of GPU compute decreases, larger models with many more parameters become possible. By building on improvements like these, we can create ever more advanced AI tutors. These tutors will be able to understand your learning goals and current understanding to create personalized curriculums that are just difficult enough to challenge and ensure long term retention.\nAdvancing AI can help close the gap that MOOCs currently have difficulty filling, and help to scale education. Increased education leads to more people with advanced degrees that can help us solve some of our most pressing challenges. These are still the early days of LLMs.\n","permalink":"https://tenzinwangdhen.com/posts/augmenting-human-intelligence-with-ai/","summary":"TLDR I created SocratesGPT to test the concept of using AI to generate questions about a given topic. Its goal you learn topics better by asking you questions about it. I also provide some technical details on the implementation.\nWhy? Over a year ago, I began using Anki, a spaced repetition flashcard app that helps me retain information over the long term by taking advantage of the Ebbinghaus forgetting curve. Memory is like a leaky bucket, and it was incredibly frustrating to realize I\u0026rsquo;d forgotten most of what I learned.","title":"Augmenting Human Intelligence With AI"}]