[{"content":"Melanie Michell is an AI researcher and professor at the Santa Fe Institute. In her book \u0026ldquo;Artificial Intelligence: A Guide for Thinking Humans,\u0026rdquo; she seeks to make artificial intelligence understandable for laypeople, and for the most part, achieves that goal. She begins by discussing the history of artificial intelligence, starting from the \u0026ldquo;perceptron\u0026rdquo; and working up to deep learning for natural language. Michell explains each concept in concrete terms and apt metaphors, with minimal technical jargon and math. Each “AI string”, heralded by new breakthroughs and followed by breathless claims about potential revolutionary applications just around the corner, are inevitably followed by “AI winters”, where the technology falls short of expectations. She also delves into philosophical concepts such as the alignment problem, the singularity, and consciousness in AI systems.\nTo quote the end of the book:\nI hope that this book has helped you, as a thinking human, to get a sense of the current state of this burgeoning discipline, including its many unsolved problems, the potential risks and benefits of its technologies, and the scientific and philosophical questions it raises for understanding our own human intelligence. And if any computers are reading this, tell me what it refers to in the previous sentence and you’re welcome to join in the discussion.\nOne of the challenges of writing a book in such a rapidly evolving field is that it is bound to become obsolete. Mitchell does not cover newer technologies such as LLMs and stable diffusion at all. Furthermore, she makes her stance on AGI risk clear: she thinks that the existential risk from AGI detracts from the real-world consequences of much dumber AI models that are already negatively impacting us today. While I do not fully agree with her philosophical stance, the book provides a great overview of the most important AI models and their history, as well as the philosophical discourse around AI.\nPerceptron Michell describes the perceptron as a single-layer neural network that outputs a prediction based on input weights. The weights are updated using a \u0026ldquo;loss function\u0026rdquo; with the goal of minimizing the loss over multiple iterations to achieve more accurate predictions. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory, invented the perceptron. He was inspired by the way neurons process information in the brain, where adjustments to the strength of connections between neurons play a key role in learning. He was also influenced by the work of behavioral psychologist B.F. Skinner, who used rewards and punishments to train animals. In the perceptron, correct firing is rewarded, while errors are punished.\nTo simulate the different strengths of connections to a neuron, Rosenblatt proposed that a numerical weight be assigned to each of a perceptron’s inputs; each input is multiplied by its weight before being added to the sum. A perceptron’s threshold is simply a number set by the programmer.\nIn 1958, The New York Times reported on the perceptron and predicted that it would \u0026ldquo;be able to recognize people and call out their names, and instantly translate speech in one language to speech and writing in another.\u0026rdquo; This was one of the first instances of the AI hype cycle that repeats throughout the book and history. However, it was eventually found that the single-layer perceptron could only learn linearly separable problems. The required compute for more layers, and thus more complex problems, did not yet exist. As a result, Marvin Minsky declared perceptrons a \u0026ldquo;dead-end\u0026rdquo;, and research stalled for decades. This marked the start of the first “AI winter”. Perceptrons are the foundation of the current deep learning revolution, who knows how much we would have progressed had research continued uninterrupted?\nReporting on a press conference Rosenblatt held in July 1958, The New York Times featured this recap: \u0026ldquo;The Navy revealed the embryo of an electronic computer today that it expects will be able to walk, talk, see, write, reproduce itself, and be conscious of its existence. Later perceptrons will be able to recognize people and call out their names and instantly translate speech in one language to speech and writing in another language, it was predicted.\u0026rdquo;\nMulti-layer perceptron Multi-layer perceptrons (MLPs) are based on the idea of the perceptron, but are more complex. An MLP has at least three layers: the input layer, the \u0026ldquo;hidden\u0026rdquo; layer, and the output layer. The input layer takes in numbers as inputs, the hidden layer processes information from the input layer, and the output layer produces the network\u0026rsquo;s output. The additional layers enable the MLP to learn much more complex functions than a perceptron. An MLP with more than three layers is called a \u0026ldquo;deep neural network\u0026rdquo; (DNN).\nConvolutional neural networks (CNN) Convolutional neural networks, or ConvNets, are machine vision models based on key insights about the brain\u0026rsquo;s visual system, discovered by Hubel and Wiesel in the 1950s and 60s. They found that neurons in the lower layers of the visual cortex are arranged in a rough grid. Each neuron in the grid responds to a corresponding area of the visual field.\nConvNets are deep learning models that transform an input image into a set of activation maps with increasingly complex features, via \u0026ldquo;convolutions\u0026rdquo;. The lower layers detect things like edges, while higher layers detect more complex features like shapes or faces. The features of the highest layer are fed into a traditional neural network, which outputs confidence percentages for categories known to the network. The network returns the category or label with the highest confidence as the image\u0026rsquo;s classification.\nAlexNet was the first to use ConvNets for the 2012 ImageNet competition, achieving 85% accuracy. This was a significant improvement over the previous record of 72%, which was based on support vector machines. The success of AlexNet can be seen as the start of the deep learning revolution. Interestingly, Ilya Sutskever, cofounder of OpenAI, helped create AlexNet.\nAlexNet, named after its main creator, Alex Krizhevsky, then a graduate student at the University of Toronto, supervised by the eminent neural network researcher Geoffrey Hinton. Krizhevsky, working with Hinton and a fellow student, Ilya Sutskever, created a scaled-up version of Yann LeCun’s LeNet from the 1990s; training such a large network was now made possible by increases in computer power\nAlthough ConvNets are stronger than previous methods, they still have several issues. They can become confused by images that contain multiple objects, miss small objects in an image, and are easily thrown off by slight distortions and abstract representations. Additionally, they have been known to display bias. For example, the Google Photos app infamously tagged an image of two African Americans with the label \u0026ldquo;gorillas\u0026rdquo;. While CNNs excel at categorization, they still struggle with localization tasks, such as drawing a box around the target object.\nIf the goal of computer vision is to “get a machine to describe what it sees,” then machines will need to recognize not only objects but also their relationships to one another and how they interact with the world. If the “objects” in question are living beings, the machines will need to know something about their actions, goals, emotions, likely next steps, and all the other aspects that figure into telling the story of a visual scene\nReinforcement Learning Unlike supervised learning, reinforcement learning doesn\u0026rsquo;t require labeled data for training. Michell uses the analogy of a dog finding the path to food. The dog (agent), takes actions over a series of \u0026ldquo;learning episodes\u0026rdquo;, which consist of some number of \u0026ldquo;iterations\u0026rdquo;. At each iteration, the agent determines the current state and chooses the next action to take. If the agent receives a reward, it has \u0026ldquo;learned\u0026rdquo; something. The agent must balance between exploring new paths versus exploiting successful paths.\nThe promise of reinforcement learning is that the agent—here our robo-dog—can learn flexible strategies on its own simply by performing actions in the world and occasionally receiving rewards (that is, reinforcement) without humans having to manually write rules or directly teach the agent every possible circumstance.\nDeepMind used deep reinforcement learning to first beat Atari games, and then famously the board game \u0026ldquo;Go\u0026rdquo; with AlphaGo. Mitchell describes it as “the ultimate idiot savant”, since it can only play Go very well but that intelligence fails to generalize to other tasks.\nNatural language processing (NLP) After the 1990s, rule-based approaches to NLP were overshadowed by more successful statistical approaches that used massive datasets to train machine learning algorithms. Mitchell describes several of the newer algorithms and techniques, including recurrent neural networks (RNNs), long-short term memory (LSTM), and word vectors.\nWord vectors embody the dictum, \u0026ldquo;you shall know a word by the company it keeps\u0026rdquo;. Words are converted into numbers that are then mapped (embedded) into a semantic space. Here, similar words like \u0026ldquo;king\u0026rdquo; and \u0026ldquo;queen\u0026rdquo; are closer together than \u0026ldquo;king\u0026rdquo; and \u0026ldquo;basketball\u0026rdquo;. This allows computers to \u0026ldquo;reason\u0026rdquo; about the meaning of words, enabling calculations such as \u0026ldquo;king\u0026rdquo; + \u0026ldquo;queen\u0026rdquo; - \u0026ldquo;woman\u0026rdquo; = \u0026ldquo;prince\u0026rdquo;. This is one of the key ideas behind more intelligent technologies, such as semantic search and ChatGPT.\nMitchell discusses the use of these technologies in tools like Google Translate. While deep learning performs remarkably well at translation, she doubts it will match the expertise of human translators for some time. This is because these technologies lack common sense knowledge and do not truly comprehend the content they are processing.\nI’m skeptical that machine translation will actually reach the level of human translators—except perhaps in narrow circumstances—for a long time to come. The main obstacle is this: like speech-recognition systems, machine-translation systems perform their task without actually understanding the text they are processing\nThe book is starting to show its age because it doesn\u0026rsquo;t mention transformers, the most powerful NLP system yet created and used in ChatGPT.\nThe Turing test Alan Turing predicted that in 50 years, computers would be able to trick humans into thinking they are humans about 70% of the time. This became known as the \u0026ldquo;Turing test\u0026rdquo;. In 2014, a group of Russian and Ukrainian programmers won a competition held by the Royal Society by fooling 10 of 30 judges into thinking it was human.\nTuring did not specify the criteria for selecting the human contestant and the judge, or stipulate how long the test should last, or what conversational topics should be allowed. However, he did make an oddly specific prediction: “I believe that in about 50 years’ time it will be possible to programme computers … to make them play the imitation game so well that an average interrogator will not have more than 70 percent chance of making the right identification after five minutes of questioning.” In other words, in a five-minute session, the average judge will be fooled 30 percent of the time.\nThere is now a modified Turing test, designed by Kapor and Kurzweil and to be carried out by 2029. Three humans and one AI will be interviewed by three judges for two hours. The AI passes if it fools two or more judges. Kapor believes that machines will never pass the Turing test without the equivalent of a human body, while Kurzweil believes that AGI is imminent.\nMitchell Kapor. He made a negative prediction: “By 2029 no computer—or ‘machine intelligence’—will have passed the Turing Test.” Kapor, who had founded the successful software company Lotus and who is also a longtime activist on internet civil liberties, knew Kurzweil well and was on the “highly skeptical” side of the Singularity divide. Kurzweil agreed to be the challenger for this public bet, with $20,000 going to the Electronic Frontier Foundation\nThe Singularity Mitchell shares her thoughts on the \u0026ldquo;singularity\u0026rdquo;: a future where the pace of technological change is so rapid that human life is irreversibly transformed. This idea is closely related to mathematician I.J. Good\u0026rsquo;s concept of an \u0026ldquo;intelligence explosion\u0026rdquo;, which postulates that an ultra-intelligent machine could design even more intelligent machines, leading to a recursive loop of self-improvement that would leave humans far behind. The resulting gap in intelligence could become as wide as the gap between us and ants. Ray Kurzweil, currently principal researcher, is the most famous proponent of the Singularity.\nKurzweil’s ideas were spurred by the mathematician I. J. Good’s speculations on the potential of an intelligence explosion: “Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind.\nI was inspired to pursue a career in technology after reading his book \u0026ldquo;The Singularity is Near\u0026rdquo; in college. Mitchell makes it clear that she does not believe in the Singularity. She comes close to calling Kurweil a quack, though indirectly.\nLack of common sense knowledge One of the core issues with current machine learning systems from Michell\u0026rsquo;s perspective is the lack of real understanding in these algorithms. Despite this lack, she is surprised that language translation has reached such a high level. These algorithms lack \u0026ldquo;common sense\u0026rdquo; knowledge, which is something that humans implicitly know and therefore do not explicitly write down. Instead, the machine learns from what it observes in the data, which may not align with what humans would observe. A good example of this is the Winograd schemas, which are sentences where changing one word of the question changes the expected answer.\nMichell tells the colorful story of \u0026ldquo;Clever Hans\u0026rdquo;. This horse gained fame because people believed it could \u0026ldquo;calculate\u0026rdquo;. When asked a question like \u0026ldquo;What is 5 times 3?\u0026rdquo;, it would tap its hoof the correct number of times. However, it was eventually revealed that the horse did not actually understand math. Instead, it was responding to subtle cues given by the questioner. Michell uses this as a metaphor for something that appears to understand, but in reality, does not understand anything at all. This still holds true today, as even the best LLMs like GPT-4 are still prone to hallucinate, and certain prompts can illicit responses that make it clear that it currently has no common sense knowledge.\nThe need for embodiment According to Mitchell, the primary mode of human learning is experiential, with book learning as an added layer. She argues that AI can never attain a common sense understanding if it does not have a physical presence and experience in the real world. In support of this, she quotes Andrei Karpathy, who suggests that to build computers capable of interpreting scenes like humans, we may need to provide them with exposure to years of structured, temporally coherent experience, the ability to interact with the world, and some form of magical active learning/inference architecture that is currently difficult to imagine.\nShe quotes Karpathy:\nA seemingly inescapable conclusion for me is that we may … need embodiment, and that the only way to build computers that can interpret scenes like we do is to allow them to get exposed to all the years of (structured, temporally coherent) experience we have, ability to interact with the world, and some magical active learning/inference architecture that I can barely even imagine when I think backwards about what it should be capable of.\nPredictions At the end of her book, Michell lists some predictions for some of the most pressing questions in AI. She does not believe that mass unemployment or fully autonomous self-driving cars will happen anytime soon. According to her, creativity is not just about generating content, but also requires the ability to judge and understand what has been created. Therefore, AI is not creative in the full sense of the word. Mitchell also does not believe in an intelligence explosion or the singularity.\nAbove all, the take-home message from this book is that we humans tend to overestimate AI advances and underestimate the complexity of our own intelligence. Today’s AI is far from general intelligence, and I don’t believe that machine “superintelligence” is anywhere on the horizon. If general AI ever comes about, I am betting that its complexity will rival that of our own brains.*\nIn fact, she states that the opposite of superintelligence is the problem: much dumber AI systems already deployed at scale causing issues such as bias, economic displacement, and increasing radicalization.\nI think the most worrisome aspect of AI systems in the short term is that we will give them too much autonomy without being fully aware of their limitations and vulnerabilities. We tend to anthropomorphize AI systems: we impute human qualities to them and end up overestimating the extent to which these systems can actually be fully trusted.\nIn response to the question of how far away we are from achieving AGI, Michell quotes Oren Etzioni, director of the Allen Institute for AI, who said, \u0026ldquo;Take your estimate, double it, triple it, quadruple it. That\u0026rsquo;s when.\u0026rdquo;\nIt\u0026rsquo;s an interesting thought that what are perceived to be human limitations - such as biases, emotions, and cognitive shortcomings - may actually enable humans to possess general intelligence.\nClosing thoughts Mitchell expresses a healthy dose of skepticism about the capabilities of AI, which may serve as a good antidote to the current massive hype cycle. Given AI\u0026rsquo;s history, it\u0026rsquo;s likely that we\u0026rsquo;ll experience another \u0026ldquo;AI winter\u0026rdquo; where the touted benefits never materialize. However, as the book contains the word \u0026ldquo;guide\u0026rdquo; in its title, it would be preferable if it were not biased in either direction. While it\u0026rsquo;s important to solve current issues with \u0026ldquo;dumb\u0026rdquo; AI, I believe that mitigating existential risks from AI is also necessary. I lean more towards the positive end of the AI doomer to AI enabled utopia spectrum, and believe that AGI aligned with human values may be the last invention humans need to make. Despite this, I would recommend this book to non-technical friends who want an accessible primer on the field of artificial intelligence.\n","permalink":"https://tenzinwangdhen.com/posts/ai-for-thinking-humans/","summary":"Melanie Michell is an AI researcher and professor at the Santa Fe Institute. In her book \u0026ldquo;Artificial Intelligence: A Guide for Thinking Humans,\u0026rdquo; she seeks to make artificial intelligence understandable for laypeople, and for the most part, achieves that goal. She begins by discussing the history of artificial intelligence, starting from the \u0026ldquo;perceptron\u0026rdquo; and working up to deep learning for natural language. Michell explains each concept in concrete terms and apt metaphors, with minimal technical jargon and math.","title":"Book Review - Artificial Intelligence: A Guide for Thinking Humans"},{"content":"Generative AI PC Build Log Why With the emergence of generative AI, I finally had a compelling reason to build a new PC. Most deep learning projects require a dedicated GPU, making them difficult to run even on an M1 MBP. While cloud options like Paperspace and Colab exist, the GPUs they provide access to are limited. Paperspace, for instance, only allows access to the most basic GPU and denied my request for access to the RTX 4000. AWS was also an option, but it was somewhat inconvenient to use cost-effectively since you would have to stop the instance and snapshot the volume to save on costs. Having a local GPU is crucial to quickly run experiments at a small scale before deploying them to the cloud to run on bigger hardware. This helps me minimize the feedback loop and make faster progress. I had previously built a computer a couple of times in high school, mostly for gaming. I didn\u0026rsquo;t have a good reason to do it again until now.\nAnother option would have been to buy a pre-built RTX 4090 rig, which would have been easier. However, it would have provided less value for the money, with cheaper components. By building my own computer, I was able to get twice the amount of RAM, a larger SSD, and a nicer case for the same price as the pre-built option. Additionally, building my own rig provided a learning experience and made me more comfortable with changing out parts if necessary.\nBuild Specs CPU: Intel Core i9-13900K 3 GHz 24-Core RAM: 4x 32gb DDR5-6400 GPU: Gigabyte RTX 4090 Power supply: 1000W Corsair modular power supply Motherboard: MSI MPG Z790 EDGE Wifi Case: Lian Li Dynamic EVO SSD: 2TB Samsung 990 Pro Parts list: https://pcpartpicker.com/b/rZqp99\nPicking the parts When I was picking the parts for my PC build, I started by researching on PC Parts Picker. I was looking for a builds that included the RTX 4090, currently the most powerful consumer GPU. Most people seemed to be building for gaming or content production use cases, but the requirements for deep learning are not that different. The main thing is having a powerful GPU. Using PC Parts Picker, I was able to come up with a list of everything I needed and gradually swapped things out as I did more research on parts.\nI got all the parts on Amazon. I considered Newegg, but heard some horror stories online about Newegg making it very difficult to return defective parts. Amazon has a no questions asked return policy, which I did end up using for one of my RAM sticks with broken RGB.\nGPU I had already decided on the RTX 4090 as the centerpiece of my build. The only alternative would have been the RTX 3090, which has 50% fewer CUDA cores and lower performance in training throughput, as well as being less power efficient. However, the 4090 has the same amount of VRAM as the 3090, and costs about $1600 vs $1000 for the 3090.\nThe choice was mainly between the top-rated 4090 cards on Amazon, and I ultimately decided on the Gigabyte 4090 due to its positive reviews and quick shipping.\nCPU The decision was between Intel and AMD, specifically the Intel 13900K versus the AMD 7950X. The general consensus is that AMD provides better value for money but runs hotter. Although the 7950X used to be about $100 more expensive, the prices are now the same. While Intel has 8 more cores, AMD has a 5nm TSMC chip and a larger L3 cache, which can benefit machine learning workloads.\nIn the end, I chose the 13900K, but I would have chosen AMD if the prices were the same. For machine learning use cases, most of the load will be on the GPU anyway. Although the AMD Threadripper is the absolute best CPU for machine learning, its price tag of over $1k is prohibitive for hobbyists.\nMotherboard This one took a lot of research. My criteria were to find a motherboard that supports the Intel 13th gen chip, DDR5 RAM, and has built-in wifi, and is also reasonably future-proof. I initially started looking at the ASUS ROG Strix Z790-E, but some concerning reviews about reliability swayed me to look elsewhere. I really didn\u0026rsquo;t want to flash the bios to enable the motherboard to work with the latest Intel chip, but that seemed unavoidable unless I was willing to shell out for the most expensive motherboards. Eventually, I landed on the MSI MPG Z790 EDGE WIFI, which had solid reviews and offered good value for the price.\nFor those with a larger budget who want a 2x 4090 setup, you’ll need to consider a motherboard that supports two GPUs. This will also require a larger power supply and case, and possibly a beefier CPU like the AMD Threadripper for the additional PCIe lanes.\nCase This was a bit tricky. The 4090 is a huge card, so I needed a case that could contain it and be reasonably easy to build in. Several builds on PC Part Picker used Lian Li cases. While I liked the idea of going with the smaller Lian Li Dynamic Mini, the build seemed too adventurous for me. The last thing I wanted was to have to start over because something didn\u0026rsquo;t fit in the case. So I went with the Dynamic Evo.\nRAM Pretty easy choice here. I knew I wanted DDR5, which can be 50% faster than DDR4. I went with the G.Skill Trident Z5 since it was a popular option.\nPower supply The 4090 requires at least 450W. The i9 pulls up to 253W. So I went with a 1000W power supply. The Corsair I landed on is also fully modular, which made it easy to only connect the cables I actually needed.\nSSD This was an easy choice. I definitely wanted an NVMe for my main drive, and the Samsung is known to be reliable.\nAssembly Recommended Tools: Phillips #2 Screwdriver with magnetic tip. The magnetic tip came in really handy to pick up tiny screws. Zip ties. I got a variety pack from Amazon. Didn\u0026rsquo;t end up using too many, but good to have on hand. A bowl to hold loose screws. A bright work lamp. Optional: Anti-static wrist strap. I had this and started using it, but it was pretty restrictive to have on and I ended up doing most of the build without it. Updating the BIOS The first critical task I tackled was updating the BIOS on the motherboard. Thankfully, this process was pretty straightforward. There are numerous Youtube videos describing the process for any given motherboard.\nDuring the process, I noticed that the PSU showed no signs of life when connected to the motherboard, which gave me a moment of concern. I thought I received a defective unit and decided to test it using the \u0026ldquo;paper clip test.\u0026rdquo; When the PSU fans roared to life during the test, I realized they don\u0026rsquo;t activate unless under load.\nInstalling the CPU Next on the list was the CPU. The process was smooth and relatively easy to execute. It’s a simple matter of lining up the arrows on the board with the ones on the chip. It is a delicate process though, make sure you don’t bend or touch any pins or get dust in the socket or the chip.\nSnapping the RAM Into Place Installing the RAM was literally a snap. The only product defect I ran into during the build was that one of my RAM sticks did not light up. I was able to get it replaced via Amazon very easily with no questions asked.\nAside on overclocking: The RAM advertises a top speed of 6400 MHz, but by default was only 4000. I was unable to get Windows to start after setting the speed to 6400 in BIOS, the highest I was able to get to was 5600 MHz. This resulted in a 10% performance increase on the Time Spy 3d Mark test.\nNVMe SSD Installation I had to look up how to remove the cover on the motherboard for the SSD slot, but after that it was just a matter of screwing the SSD into place.\nCase Setup This is where things got somewhat hairy. The Lian Li case instructions are not super clear, and there are a million parts to deal with. It really helps here to stay organized and know where you place every screw. Use a bowl for loose screws. Thankfully there are a few good videos on my exact case, this one was pretty good: https://www.youtube.com/watch?v=2v2fd1nrnkY\nImportant: when setting up the case is that most CPU coolers require attaching a plate to the back of the motherboard. Do this before screwing the motherboard into the case to avoid any unnecessary backtrack.\nOnce the case was prepped, I screwed the motherboard into place.\nCase Fans This probably took the most time. I had to spend quite a bit of time thinking through fan placement. I had ordered 9 Lian Li SL-Infinity fans, by far the most case fans I\u0026rsquo;ve ever put into a PC. There\u0026rsquo;s some theory on the best fan placement to reduce dust build up and improve airflow. I ended up going with three intake on the bottom and one in the back, and two exhaust on the side and three on top.\nThe nice thing about the Lian Li fans was that they daisy chain pretty easily, so a set of three fans could be powered by a single cable. That cable then connects to a central hub that can be connected to up to four sets of fans, which is powered by a single cable from the power supply. The one issue was I had a hard time figuring out which side was the face (intake). It turned out that in my version, the mirrored side is the face. Lots of screwing fans in and out involved.\nApplying Thermal Paste Once all the fans were in place, I was ready to apply the thermal paste. The NZXT CPU cooler came with some preinstalled, but I saw it\u0026rsquo;s recommended to apply your own. I went with the technique of manually spreading the paste with the provided tool.\nInstalling the CPU Cooler The NZXT Kraken Elite is an \u0026ldquo;all-in-one\u0026rdquo; liquid CPU cooler that pumps cold liquid to the CPU and warm liquid back through a radiator. It comes with its own fans, but they did not work well with the Lian Li fans. The Kraken fans require their own controller hub, and the RGB did not sync well. Additionally, I had run out of RGB slots on the motherboard, so I used the Lian Li fans on the NZXT filter instead.\nPutting the head of the cooler on the CPU was actually pretty easy.\nFitting the GPU The 4090 is a beast of a GPU, taking up 3.5 PCIe slots. Thankfully it fit in the case with plenty of room. Installation proved pretty easy. Apparently the Lian Li case allows for vertical mounting of the GPU with a supplied bracket, but I didn\u0026rsquo;t really want to bother with that.\nI got scolded by folks on PC Parts Picker for not installing the GPU bracket. This was included with the Gigabyte RTX 4090, but I avoided installing it because my JUSB4 connector was too big and blocked the top part of the bracket. The GPU also seemed stable enough without it. However, it seems that the GPU is so large that overtime it will sag and potentially break the PCIe slot or the GPU itself. I ended up installing the bracket after all, I can live without a front panel USB-C port.\nConnecting Power Supply Since I got a modular power supply, I had to figure out exactly which cables I needed for all of the components. I hooked up the required cables to the power supply and routed the cables through the holes in the case to the components.\nTest Run At this point all of my main components were in. I connected all of the various wires to the motherboard. This was pretty easy because as long as you read the labels and connect the wires to the matching pins without forcing anything, it\u0026rsquo;s basically like legos.\nThankfully nothing blew up when I flipped the switch. I made sure that the computer booted up properly before moving on to cable management and cleanup.\nCable Management Managing the cables turned out to be relatively straightforward with the Lian Li case. All cables could be hidden at the back and fed through rubberized slots around the motherboard. After organizing the mess, a provided plate neatly covered the center gap in the case.\nInstalling Windows and Drivers You’ll need to create a bootable Windows USB on another Windows PC. I thankfully have Parallels Desktop on my Mac, so I was able to do this pretty easily. You also need a wired Ethernet connection and wired mouse and keyboard, since wifi and bluetooth don’t work without the necessary drivers installed. Once you get through the Windows installation process and install the drivers, you should be good to go!\nBenchmarks Cinebench 3d Mark https://3dmark.com/spy/39191470\nGenerative AI performance Stable Diffusion This thing can crank out basic 512x512 images in seconds, much faster than what my M1 Macbook Pro can do. I do run into CUDA out of memory errors if I try to upscale images too much, but for rapid iteration it\u0026rsquo;s great.\nimg2img of a screenshot of the completed build, with prompt: \u0026ldquo;futuristic cyberpunk gaming computer,neon,4k,highly detailed,large graphics card,water cooling,glowing\nLLAMA I\u0026rsquo;m able to load llama-7b fully on the GPU, and inference is very fast. The generated text is trash. Llama-14b requires putting some layers on the CPU, slowing down inference substantially, and the larger models are basically unusable. This is where a dual GPU setup would be nice. As LLMs get more efficient, I think this will be less of an issue.\nFinal Thoughts After several years of working with disembodied infrastructure in the cloud, there is something refreshing about working with physical hardware larger than a Raspberry Pi. Going through this experience was definitely a great learning opportunity, and I recommend doing it yourself if you have similar requirements. I hope you found this useful as another data point in your research.\n","permalink":"https://tenzinwangdhen.com/posts/ml-pc-build-log/","summary":"Generative AI PC Build Log Why With the emergence of generative AI, I finally had a compelling reason to build a new PC. Most deep learning projects require a dedicated GPU, making them difficult to run even on an M1 MBP. While cloud options like Paperspace and Colab exist, the GPUs they provide access to are limited. Paperspace, for instance, only allows access to the most basic GPU and denied my request for access to the RTX 4000.","title":"2023 Generative AI PC Build Log"},{"content":"A Time Capsule of Startup Interviews \u0026ldquo;Founders at Work\u0026rdquo; by Jessica Livingston is a chronicle of startup stories, mostly from startups in the 80s and 90s. The book consists of a series of interviews between Livingston and the founders or early employees of various startups. It feels similar to tuning into a podcast from a decade or two ago, reminiscent of modern equivalents like \u0026ldquo;How I Built This\u0026rdquo; or \u0026ldquo;The SaaS Podcast\u0026rdquo;. With 32 interviews, the book offers a fascinating peek into the early days of several notable startups. Livingston, as one of the founders of the famous startup incubator Y Combinator, is well-suited to act as the interviewer.\nThe Allure of Hard Problems In the realm of startups, hard problems possess a peculiar charm. They attract the best minds, acting as a beacon for those who dare to challenge the status quo. TiVo, a company that dared to redefined how we watch TV, or Apple, where Steve Wozniak\u0026rsquo;s passion for designing elegant and simple computers led to the birth of one of the most influential tech companies. Brewster Kahle of Alexa Internet advises, \u0026ldquo;Pick a big, difficult project that will take years; otherwise, once you make money, you\u0026rsquo;ll run out of things to work on.\u0026rdquo; Similarly, Charles Geschke of Adobe Systems suggests it is wise (but risky) to develop a solution for where the market will be in a few years and wait for it to catch up, instead of just solving today\u0026rsquo;s problems.\nUnderstand your Customer The book emphasizes the importance of understanding your customers. Joel Spolsky, co-founder of Fog Creek Software, advises founders to engage with their customers, understand their needs, and disregard the competition. Sabeer Bhatia, co-founder of Hotmail, and Mark Fletcher, founder of ONElist and Bloglines, stress the value of a large user base, which provides a competitive advantage that is difficult to replicate and aids in potential acquisition negotiations.\nIdeally, you are your own customer and can adapt your product to meet your own needs that other companies also happen to have. A great example of this is Basecamp, which 37signals used to manage the Basecamp project itself. Designing a product for someone who is not you is difficult, so usability testing and customer interviews become even more important. A great product is often the best form of marketing, since your customers themselves will market the product if they love it and have the tools to do so.\nRemain Flexible Many startups initially set out to solve one problem, but ended up finding success in a different area. For example, PayPal began as a payments solution for PalmPilots, Hotmail started as a database, and Flickr started by designing a video game. Some companies even started as consulting businesses and then ended up creating products. Like unhappy families, all successful startups seem to find success in their own way.\nUltimately, great teams are more important than great ideas. They can pivot and adapt as requirements change, leading to success even in unexpected areas.\nVenture Capitalists: A Double-Edged Sword Throughout the book, Venture Capitalists (VCs) are frequently mentioned and often portrayed unfavorably. Paul Graham, co-founder of Viaweb, warns that money raised from VCs \u0026ldquo;will literally be pulled out of your ass\u0026rdquo;. ArsDigita, a company that accepted VC funding to expedite the IPO process, ended up ousting its founder and replacing management, leading to its downfall. (Although Joel Spolsky later notes that its lucrative consulting business was also drying up.) Steve Perlman of WebTV had another blunt take, saying VCs might see your company as carrion to sell for parts if it seems to be running out of money. VCs, driven by the need for exponential growth, may turn a successful company in the eyes of its founders into a \u0026ldquo;zombie.\u0026rdquo; The general consensus leans towards avoiding raising money if possible, and many founders highlight the importance of frugality.\nStartup Failures The book avoids the common pitfall of only highlighting successful startups, which can lead to survivorship bias. Instead, it openly discusses failures, such as ArsDigita and Alexa Internet, providing a balanced perspective on the startup journey. The book offers contradictory advice, acknowledging that there is no one-size-fits-all approach to building a successful startup. As Arthur van Hoff, co-founder of Marimba, wisely advises, \u0026ldquo;Don\u0026rsquo;t be afraid to listen to your gut instead of taking advice.”\nCritique I didn\u0026rsquo;t realize that Livingston was one of the founders of Y Combinator until the end of the book. This information would have been helpful earlier on to provide context. Additionally, I was expecting the book to be more prescriptive about how to work as a founder, but instead it was in an interview format.\nDespite this, the book provides a lens into startup culture during a unique time in Silicon Valley. Many of the companies mentioned were unfamiliar to me, and the technologies discussed are primitive compared to what we have today. However, much of the advice remains relevant since it mostly has to do with human nature.\nOverall, I would recommend this as entertaining light reading to anyone interested in startups, entrepreneurship, or the tech industry.\nMy rating: 4/5\n","permalink":"https://tenzinwangdhen.com/posts/book-review-founders-at-work/","summary":"A Time Capsule of Startup Interviews \u0026ldquo;Founders at Work\u0026rdquo; by Jessica Livingston is a chronicle of startup stories, mostly from startups in the 80s and 90s. The book consists of a series of interviews between Livingston and the founders or early employees of various startups. It feels similar to tuning into a podcast from a decade or two ago, reminiscent of modern equivalents like \u0026ldquo;How I Built This\u0026rdquo; or \u0026ldquo;The SaaS Podcast\u0026rdquo;.","title":"Book Review - Founders at Work"},{"content":"Summary Made to Stick, by Chip and Dan Heath, explores the art of crafting memorable and influential ideas by outlining six key principles: Simplicity, Unexpectedness, Concreteness, Credibility, Emotions, and Stories (SUCCESs). Through engaging examples and stories, the book demonstrates how to apply these principles to create \u0026ldquo;sticky\u0026rdquo; ideas that leave a lasting impact. By overcoming the \u0026ldquo;Curse of Knowledge\u0026rdquo; and employing the SUCCESs framework, readers can improve their communication skills across various fields and contexts. Made to Stick offers practical guidance, backed by research, to help anyone create and share ideas that resonate with their audience.\nThe SUCCESs Framework The authors identify six key principles, encapsulated in the acronym SUCCESs:\nSimplicity: Aim for simplicity and conciseness. Distill the core message down to its essential elements, making it easy for people to understand and remember.\nExample: Using \u0026ldquo;jaws in space\u0026rdquo; to describe the high-concept movie \u0026ldquo;Alien\u0026rdquo; Unexpectedness: Capture attention by surprising your audience. Use unexpected information or stories to break through the noise and create a memorable impression.\nExample: The \u0026ldquo;Kidney Heist\u0026rdquo; legend, where a man wakes up in a bathtub full of ice and his kidneys removed. Concreteness: Use vivid, tangible language and examples to convey your ideas. Abstract concepts are harder to remember, so anchor your message in relatable, concrete terms.\nExample: The \u0026ldquo;Velcro Theory of Memory\u0026rdquo;, where an idea that has more sensory details or concepts are more likely to stick in people\u0026rsquo;s minds. A robbery description that vividly describes the stolen goods, the suspect\u0026rsquo;s appearance, and location are more memorable than an abstract description. Credibility: Enhance the believability of your message by providing credible sources, statistics, or testimonials. Leverage internal credibility, such as personal experience, as well as external credibility from authorities or experts.\nExample: The \u0026ldquo;Sinatra Test\u0026rdquo;, named after Frank Sinatra\u0026rsquo;s lyric \u0026ldquo;If I can make it there, I can make it anywhere\u0026rdquo;, referring to New York. Provides the example of a chef that earned his credibility by working at a prestigious restaurant in NYC. Emotions: Tap into emotions to create a deeper connection with your audience. Messages that evoke strong feelings, whether positive or negative, are more likely to be remembered and acted upon.\nExample: The story of Jared Fogle, of Subway fame. His personal story connected with people on an emotional level, making the advertising campaign more memorable and impactful. Stories: Use storytelling to engage your audience, make your ideas more relatable, and facilitate learning. Well-crafted stories help people visualize, understand, and remember your message.\nExample: A story about a Nordstrom salesperson that accepted a returned set of tires, even though the store doesn\u0026rsquo;t sell tires. The story illustrates the company\u0026rsquo;s commitment to exceptional customer service. The curse of knowledge The \u0026ldquo;Curse of Knowledge\u0026rdquo; is a central concept in Made to Stick. It refers to the cognitive bias where individuals with a certain level of knowledge or expertise struggle to imagine what it\u0026rsquo;s like to not possess that knowledge. As a result, they often have difficulty communicating their ideas to those with less knowledge, using jargon or abstract concepts that are hard to understand. This is why those who have just learned about a topic are often the best teachers.\nOvercoming the curse of knowledge is key to creating sticky ideas. The book has some recommendations:\nSimplify your message Use analogies and examples. Tap into schemas that are already familiar to the audience Test your message on a small group that represents your target audience Adjust your language and level of detail based on the audience What I liked \u0026ldquo;Made to Stick\u0026rdquo; provides a wealth of actionable advice and engaging examples. The book is well-structured, with a clear layout of the SUCCESs framework and each component of it. The principles are supported by research and real-world case studies, lending them credibility. Anyone whose job involves effectively communicating ideas can benefit from reading this book.\nWhat I didn\u0026rsquo;t like This is another book that could have been summarized in just a couple of pages, which is what I will attempt to do below. The book is filled with stories that elaborate on the key principles, but it doesn\u0026rsquo;t really explain why these principles are so effective. Instead, it repeats examples where they have been effective.\nMy Rating: 3/5\n","permalink":"https://tenzinwangdhen.com/posts/book-review-made-to-stick/","summary":"Summary Made to Stick, by Chip and Dan Heath, explores the art of crafting memorable and influential ideas by outlining six key principles: Simplicity, Unexpectedness, Concreteness, Credibility, Emotions, and Stories (SUCCESs). Through engaging examples and stories, the book demonstrates how to apply these principles to create \u0026ldquo;sticky\u0026rdquo; ideas that leave a lasting impact. By overcoming the \u0026ldquo;Curse of Knowledge\u0026rdquo; and employing the SUCCESs framework, readers can improve their communication skills across various fields and contexts.","title":"Book Review - Made to Stick"},{"content":"Kodak was once the dominant player in the photography industry, selling disposable cameras, film cartridges, and developing photos. However, they failed to invest in digital cameras, which they had invented. They were making so much money on film that they didn\u0026rsquo;t want to speed up the process of making the old technology obsolete. This approach made sense to Kodak, but customers increasingly preferred instant digital photos. Now, most Gen-Zs have probably never heard of Kodak.\nGoogle is currently the dominant player in the search industry, with almost 94% market share worldwide. Its lucrative business is being the gatekeeper between you and information. To users, its services are free, as the company earns revenue through targeted advertising slots displayed at the top of search results. Google\u0026rsquo;s advanced AI helps users find information, but its primary goal is to encourage ad clicks.\nEnter ChatGPT. Rather than searching on Google and browsing multiple sites, ChatGPT engages users in conversation, providing precise information without ads. But it has its flaws. Critics dubbed it a bullshitter and a stochastic parrot, hallucinating so much it must have macrodosed. However, the release of GPT-4 significantly enhanced ChatGPT, causing some critics to shift from skepticism to apprehension.\nSuddenly, it doesn’t seem inevitable that Google will rule the universe with the most advanced AI and the most data. Ironically, Google invented the transformer, the \u0026ldquo;T\u0026rdquo; in \u0026ldquo;GPT,\u0026rdquo; but failed to invest sufficiently in its commercialization. This hesitance partially stems from the \u0026ldquo;innovator\u0026rsquo;s dilemma,\u0026rdquo; as described by Clayton Christensen. Established industry giants try to milk their aging but highly profitable technology until disruptive newcomers eat their lunch with incrementally improved innovations.\nEven when aware of the innovator\u0026rsquo;s dilemma, companies can still be disrupted by new technologies they fail to invest in. Andy Grove invited Clayton Christensen to discuss the innovator\u0026rsquo;s dilemma at Intel, yet Intel still succumbed to it. Intel clung to its outdated but lucrative x86 architecture and missed out on ARM, effectively losing the mobile market to Apple. Presently, Intel lags at least two chip generations behind TSMC.\nGoogle is making a killing on selling search ads. Replacing their search with LLM-based search would result in fewer searches, since users would find information faster without clicking on ads. While Google\u0026rsquo;s cost per search query is 1.06 cents, ChatGPT\u0026rsquo;s estimated cost per query is 36 cents. At Google\u0026rsquo;s scale, this translates to a $36B reduction in operating income. Google faces an innovator\u0026rsquo;s dilemma: whether to invest in a superior technology that could potentially cannibalize its profits.\nUnlike newcomers such as OpenAI and you.com , Google is a public company with shareholders to consider and a massive workforce of 190,000 employees. Even if CEO Sundar Pichai advocates for a full commitment to LLMs, he may struggle to gain shareholder support. Co-founders Larry Page and Sergey Brin would need to exercise their super-voting shares to redirect the company.\nTo be fair, Google is not completely sitting on its hands. It launched Bard, a ChatGPT competitor, which initially used the smaller LaMDA model but now employs PaLM , outperforming GPT-3 in some tests. Google also owns DeepMind and Anthropic, two of the most advanced AI teams in the field, and possesses one of the world\u0026rsquo;s largest data sets, crucial for training language models. However, Google had similar advantages before, such as in cloud computing, only to be outmaneuvered by more agile competitors like Amazon. The crucial question remains: Can Google invest sufficiently in this emerging technology to fend off disruption to their core business?\n","permalink":"https://tenzinwangdhen.com/posts/google-innovators-dilemma/","summary":"Kodak was once the dominant player in the photography industry, selling disposable cameras, film cartridges, and developing photos. However, they failed to invest in digital cameras, which they had invented. They were making so much money on film that they didn\u0026rsquo;t want to speed up the process of making the old technology obsolete. This approach made sense to Kodak, but customers increasingly preferred instant digital photos. Now, most Gen-Zs have probably never heard of Kodak.","title":"Google's Innovator's Dilemma"},{"content":"TLDR: I built a semantic movie search app with GPT-4. You can check it out here: https://moviesgpt.net/. And here\u0026rsquo;s the Github repo: https://github.com/sinzin91/moviesGPT\nthe hero keeps forgetting who he is\nIdea I\u0026rsquo;ve been thinking a lot about potential products that one can build around LLMs. One idea I mentioned jokingly to some friends was to use GPT as a natural language interface to a movies API.\nIn theory, I thought, you could ask GPT about movies semantically, meaning you could search based on what the movie is about or its content, instead of just raw keyword search. For example, I could search for \u0026ldquo;movies where all the main characters die\u0026rdquo; and get back \u0026ldquo;The Departed\u0026rdquo;. Then I could use the response to query a movies API like The Movies Database. Google is surprisingly bad at this, returning links to listicles instead of the movies themselves.\nThe current way to do this, and the one that even ChatGPT recommends, is to gather data on all the movies, generate word embeddings on that data, store it in a Vector database, and then query using something like cosine similarity. But GPT-3, having been trained on all internet data, has \u0026ldquo;seen\u0026rdquo; every movie and discussion around every movie already. It already has the embeddings. And it already \u0026ldquo;knows\u0026rdquo; how to find those movies given the right prompt.\nImplementation With this rough sketch of an idea, I sipped some coffee and entered this into GPT-4:\nYou are a master professional front end React developer. Show how you would build a front end that includes a search bar at the top. Below the search bar are six cards which include the movie cover with the title below it. Searches hit The Movie Database api\u0026#39;s search endpoint with the search term. The results from the API call are used to update the cards below the search bar. The site uses a black and blue, dark mode style theme, with minimal UI components. I basically just wrote that off the cuff with no large amount of premeditation, and got back a very reasonable starting place for my app: Note: I am a hobbyist front-end engineer at best and only know enough React and Javascript to be slightly dangerous. I absolutely hate CSS, and can\u0026rsquo;t remember the difference between align-items and justify-content to save my life.\nTo my surprise, I was able to just copy paste the code from GPT-4 to get a decent looking site!\nI then asked to change it so that it calls OpenAI first:\nOk great! Now I want you to change it so that searches are sent to OpenAI\u0026#39;s text-davinci-003 API. Hit The Movies Database API with each element from the returned array, and render those movies in the MovieGrid. Interestingly, GPT generated a prompt from my prompt:\nconst response = await openai.Completion.create( { engine: \u0026#34;text-davinci-003\u0026#34;, prompt: `Find 6 movie titles related to \u0026#34;${searchTerm}\u0026#34;` }) This prompt is not precise enough though, so here I actually had to do some work:\nReturn an array of movie titles that best match this search term, ordered from most to least relevant. Generate up to 16 titles. If you are unable to answer the question, start your response with Sorry. Example: prompt: \u0026#34;movies with brando\u0026#34; response: [\u0026#34;The Godfather\u0026#34;, \u0026#34;The Godfather: Part II\u0026#34;, \u0026#34;Apocalypse Now\u0026#34;, \u0026#34;The Wild One\u0026#34;] prompt: ${searchTerm} response: I\u0026rsquo;m giving GPT an example of the kind of response I expect. In this case, I want it to create a valid array of movie titles.\nWith this change, I had the first working POC of my original idea! The last time experienced such a sensation of god-like empowerment might have been unlocking robots in Factorio.\nin Factorio, eventually you can have robots automatically build things based on blueprints\nWhew, okay, great. Now what?\nI showed the app to a friend, and he mentioned that it looked terrible on mobile. So I asked GPT-4 to \u0026ldquo;change the CSS so the website works well on mobile phones.\u0026rdquo; Lo and behold, after copying over the CSS directly, the site worked flawlessly on mobile. No futzing with media queries for me!\nI also realized that I wanted to add star ratings to these movies to get a sense of their popularity. The TMDb API returns \u0026ldquo;vote_ratings,\u0026rdquo; which is a number from 0 to 10. I found the distribution of \u0026ldquo;vote_ratings\u0026rdquo; here: https://www.kaggle.com/code/erikbruin/movie-recommendation-systems-for-tmdb.\nAdding a stars component was also mostly copy/paste once I wrote the prompt:\nThe movie database api returns a `vote_average` in the response. I want a \u0026#34;Stars\u0026#34; component below each movie title that gives gives the movie 1 star if `vote_average` is between 0 to 2, 2 stars if it is between 2 to 4, etc. If a movie got one star, there should be a single bright yellow star and four grey stars in the component. I also wanted something to happen when I clicked on the cards. Maybe show the movie summary, release date, etc. Here\u0026rsquo;s the prompt: One thing that was bothering me in terms of practical usability was the lack of Rotten Tomatoes ratings. Often, that\u0026rsquo;s the first thing I check when deciding whether to watch a given movie. Unfortunately, Rotten Tomatoes charges $60k/year (!!) for access to their API. Then I had the idea of asking GPT for the Rotten Tomatoes ratings. To my surprise, it does seem to have a sense for the ratings. Although they are not fully accurate, they seem to be generally in the right ballpark.\nI updated my prompt to generate a new data structure that includes the Rotten Tomatoes ratings:\nReturn a JSON object movie titles that best match this search term and their Rotten Tomatoes tomatometer score, ordered from most to least relevant. Get the most up to date and accurate Rotten Tomatoes tomatometer score. Generate up to 12 titles. If you are unable to answer the question, return a string that starts with Sorry. The response must be a valid JSON. Example: prompt: \u0026#34;movies with brando\u0026#34; response: [ { \u0026#34;title\u0026#34;: \u0026#34;The Godfather\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 98 }, { \u0026#34;title\u0026#34;: \u0026#34;The Godfather: Part II\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 97 }, { \u0026#34;title\u0026#34;: \u0026#34;Apocalypse Now\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 96 }, { \u0026#34;title\u0026#34;: \u0026#34;The Wild One\u0026#34;, \u0026#34;rottenTomatoesScore\u0026#34;: 85 } ] prompt: ${searchTerm} response: I also had GPT make me the new Rotten Tomatoes rating component:\nNow I can safely avoid these movies!\nI was surprised by how well semantic search works out of the box with GPT. However, there are some limitations. One is that it only recognizes movies up to the date it was trained, which was late 2021. When asked about movies released after that, it simply responds that it doesn\u0026rsquo;t know. This issue may be addressed by the Plugins that OpenAI announced, which would allow GPT to call live APIs to fetch real-time data. One could also probably create a fine-tuned model that is trained on more recent movies.\ncan\u0026rsquo;t find movies from 2022\nI tried using gpt-3.5-turbo, but that model seemed to be much more prudish, refusing to respond to searches on movies deemed unseemly by the RLHF moderators. So I switched back to text-davinci-003 for now.\nLimitations To be clear, I still had to do some coding to get the functionality and styling to match exactly what I wanted. I don\u0026rsquo;t think someone without experience in React or Javascript would be able to replicate this. GPT still gets some things wrong, like telling me to use outdated libraries or generating wonky styles (who wants a blue background on a header??). But it\u0026rsquo;s getting pretty close.\nIn more ambitious projects, I\u0026rsquo;ve noticed that GPT starts to \u0026ldquo;forget\u0026rdquo; the code it had previously suggested. So when I ask to change some function, it spits out a new version of the file that has a completely different implementation and method names. Maybe this is a result of the limited context window. I\u0026rsquo;ve gotten around this by pasting in the code again and asking it to make the change given that context.\nClosing Thoughts I got the feeling that I was a tech lead pair programming with a very knowledgeable junior engineer. It doesn\u0026rsquo;t do well with big picture decisions, but knows how to implement very well given the right direction. To be fair, I\u0026rsquo;m not doing anything groundbreaking here. There must be tons of sites like this in the pretraining data, so it\u0026rsquo;s relatively easy for GPT to generate the relevant code.\nIt was also much easier to get into that elusive flow state while hacking this out. The dopamine hits from thinking of a feature and seeing it in action just kept coming, without the usual frustrations of not knowing how a particular function works and having to look it up. This makes coding fun again.\nIt\u0026rsquo;s clear that I am the bottleneck in this process. I\u0026rsquo;m sitting here copying and pasting from GPT with some slight modifications. It seems like the natural progression here is to have GPT directly create the code based on my prompts. I imagine you could build a more advanced \u0026ldquo;Create React App\u0026rdquo; that generates and updates the app based on your prompts.\nI hope this inspires people to pursue building those apps they always wanted to build, but couldn\u0026rsquo;t find time for. GPT still does not know what app to build and why it should build it, which is where we come in. Let a thousand flowers bloom!\n","permalink":"https://tenzinwangdhen.com/posts/semantic-movie-search-with-gpt/","summary":"TLDR: I built a semantic movie search app with GPT-4. You can check it out here: https://moviesgpt.net/. And here\u0026rsquo;s the Github repo: https://github.com/sinzin91/moviesGPT\nthe hero keeps forgetting who he is\nIdea I\u0026rsquo;ve been thinking a lot about potential products that one can build around LLMs. One idea I mentioned jokingly to some friends was to use GPT as a natural language interface to a movies API.\nIn theory, I thought, you could ask GPT about movies semantically, meaning you could search based on what the movie is about or its content, instead of just raw keyword search.","title":"GPT-4 made me a GPT powered movie search app"},{"content":"TLDR \u0026ldquo;Peak: Secrets from the New Science of Expertise\u0026rdquo; by Anders Ericsson challenges conventional wisdom about talent, skill acquisition, and what it takes to achieve true expertise. Ericsson, a psychologist and researcher in the field of expertise, highlights several experiments to back up his claims, although some of the cited studies had small sample sizes. Despite containing some contradictions, the book offers a fascinating exploration of the science of expertise and empowers readers to pursue their path to mastery. Ericsson demonstrates that deliberate practice, not innate talent, is the key to mastery.\nDeliberate Practice Deliberate practice, a term coined by Ericsson, refers to a focused and intentional approach to skill development. It involves consistently working on specific areas of weakness or challenge, rather than merely repeating tasks or engaging in casual practice. To achieve this, it is necessary to set clear goals, seek feedback, and engage in continuous self-assessment to refine techniques and mental representations. Deliberate practice is designed to push individuals beyond their comfort zones, leading to significant improvements in performance and the eventual attainment of expertise in a given domain.\nEricsson\u0026rsquo;s concept of deliberate practice challenges the popular notion of Malcolm Gladwell\u0026rsquo;s \u0026ldquo;10,000-hour rule.\u0026rdquo; Merely spending time on a task does not guarantee expertise. It is essential to identify areas of weakness and actively work to improve them. For example, London cab drivers have developed larger hippocampi than bus drivers due to the former having to pass an extremely difficult exam and navigate to any location in London without a map.\nEricsson details an experiment in which a subject named Steve was trained to recall up to 86 numbers in a row after two years of deliberate practice. This was a significant improvement over the standard wisdom at the time, which held that working memory can only store 7 pieces of information, plus or minus two. Steve\u0026rsquo;s success can be attributed to his background as a runner, which made him accustomed to self-development and more likely to persevere through plateaus. Effective mnemonics were key to Steve\u0026rsquo;s progress, allowing him to surpass the typical working memory limit of seven numbers. Joshua Foer\u0026rsquo;s book \u0026ldquo;Moonwalking with Einstein\u0026rdquo; got me interested in mnemonic techniques, and it is interesting to note that he consulted with Ericsson.\nNeuroscience of practice Both the brain and body adjust to maintain homeostasis, a tendency towards equilibrium. For example, during endurance training, your body will eventually build additional capillaries to increase blood flow. Similarly, with the brain, neurons that \u0026ldquo;fire together, wire together\u0026rdquo;. Practicing just beyond your comfort zone signals to your brain that it needs to change to maintain homeostasis. Simple repetition does not have this effect.\nInterestingly, Ericsson relates an experiment that showed London cabbies who passed the test and started working were less effective at general recall than the control group. This might be because the adult brain does not experience as much neurogenesis, so the process of skill acquisition involves pruning inefficient synapses to be more efficient for certain tasks. This finding might have implications for what we choose to prioritize practicing.\nEricsson also mentions skilled \u0026ldquo;three-finger\u0026rdquo; braille readers who use each of their fingers for specific parts of the task. Brain scans showed that the parts of the brain that control these fingers become enlarged to the point where they overlap. These readers develop extreme sensitivity in their fingers but can\u0026rsquo;t tell which finger is being touched. The idea that the brain is not static, but can change and adapt with directed practice, is inspiring and motivating.\nThe Innate Talent Myth Ericsson challenges the belief in innate talent by first examining the concept of \u0026ldquo;perfect pitch,\u0026rdquo; the ability to identify any note in music, which was once considered a natural gift. Ericsson cites Mozart as an example of a prodigy who possessed this ability from a young age. However, the author argues that with just a year of training a few minutes a day, almost any child can learn to develop perfect pitch, provided they begin before the age of six. Even adults are able to learn this skill, although it takes longer and more deliberate practice.\nLater in the book, Ericsson debunks the notion of the savant, who may excel in a narrow field but has limited ability in other areas. He uses the example of \u0026ldquo;Donnie,\u0026rdquo; who could identify the day of the week for any date, to illustrate his point. Ericsson shows that savants often become fixated on their interests, leading to deliberate practice and mastery in a very specific domain. Outsiders only see the results of their intense focus and dedication.\nMental Representations Ericsson\u0026rsquo;s thesis focuses on the idea that deliberate practice requires the development of efficient mental representations. This concept is similar to the idea of \u0026ldquo;mental models\u0026rdquo; popularized by Charlie Munger. Ericsson uses the example of chess players who use \u0026ldquo;chunking\u0026rdquo; to recognize patterns on the board to illustrate this idea. Through deliberate practice, masters stop seeing individual pieces and instead recognize groups of pieces forming a semantic unit.\nChess players are often portrayed in popular culture as hyper intelligent, but Ericsson mentions studies that showed that adult chess players do not have a higher IQ than average. While children with high IQs may learn the rules faster, ultimately it comes down to who practices the most. Interestingly, Ericsson notes that Go players, on average, have a lower IQ than average, despite the fact that computers have yet to beat the world\u0026rsquo;s best Go players. This was published in 2015, and since then, AlphaGo famously beat the Go world champion.\nIn several sports anecdotes, Ericsson shows that athletes can surpass their predecessors by adopting better practice techniques, which are essentially better mental representations. He emphasizes the importance of learning from experts and adopting their practice methods to improve more rapidly.\nContradictions Despite its persuasive arguments, \u0026ldquo;Peak\u0026rdquo; is not without contradictions. For instance, Ericsson claims in one section that deliberate practice is not enjoyable for practitioners, while in another he says that it is. He asserts that deliberate practice can lead to virtually any accomplishment, yet also acknowledges that certain abilities can only be developed during childhood or for those with certain genetic attributes.\nEricsson notes that younger doctors are often more effective than those with 20 years of experience because their medical school knowledge is more recent. However, he also emphasizes that mere knowledge is not enough and that one needs to acquire skills through practice. While Ericsson tried to address both sides of the argument, it would have been helpful if he were more explicit about the contradictions in his thesis.\nApplication To make the idea of deliberate practice more concrete, let\u0026rsquo;s use the example of practicing guitar every day. A naive way to practice would be to mindlessly play through the same songs repeatedly each day, failing at the same sections each time. This mindless repetition can leave you stagnating in a well-worn rut, making you feel like you\u0026rsquo;ve reached the peak of your abilities. I\u0026rsquo;ll admit, this is often how I practice guitar.\nThe deliberate practice approach, on the other hand, is to focus on the difficult portions of the songs and practice those parts intensively. Once you have mastered the songs, you move on to more challenging pieces that are just outside of your comfort zone. It helps to measure your progress and note exactly which parts are giving you issues. You can also seek out other practitioners who can provide you with better and more efficient practice techniques. Though this new approach might be less fun, it is the way to mastery (assuming that\u0026rsquo;s your goal!)\nClosing \u0026ldquo;Peak\u0026rdquo; is a captivating and insightful examination of the science of expertise. Personally, I have started exploring how I can incorporate deliberate practice into my daily habits like meditation and guitar. By uncovering the secrets of deliberate practice, Anders Ericsson has provided readers with the opportunity to pursue their own path towards mastery, regardless of their background or perceived \u0026ldquo;talent.”\n","permalink":"https://tenzinwangdhen.com/posts/book-review-peak/","summary":"TLDR \u0026ldquo;Peak: Secrets from the New Science of Expertise\u0026rdquo; by Anders Ericsson challenges conventional wisdom about talent, skill acquisition, and what it takes to achieve true expertise. Ericsson, a psychologist and researcher in the field of expertise, highlights several experiments to back up his claims, although some of the cited studies had small sample sizes. Despite containing some contradictions, the book offers a fascinating exploration of the science of expertise and empowers readers to pursue their path to mastery.","title":"Book Review - Peak: Secrets from the New Science of Expertise"},{"content":"TLDR I created SocratesGPT to test the concept of using AI to generate questions about a given topic. Its goal you learn topics better by asking you questions about it. I also provide some technical details on the implementation.\nWhy? Over a year ago, I began using Anki, a spaced repetition flashcard app that helps me retain information over the long term by taking advantage of the Ebbinghaus forgetting curve. Memory is like a leaky bucket, and it was incredibly frustrating to realize I\u0026rsquo;d forgotten most of what I learned. Anki has enabled me to confidently tackle difficult technical topics that I would have otherwise avoided.\nOne issue with Anki is that you can start to \u0026ldquo;overfit\u0026rdquo; on the questions you wrote. With Anki, you look at the card and then check the answer after trying to recall it. Once you\u0026rsquo;ve seen the answer, you rate how easily you were able to recall it, which determines when the question will reappear in your deck. Creating questions can be time consuming, so I\u0026rsquo;ve found that most of my cards end up being \u0026ldquo;cloze deletions\u0026rdquo;, i.e. fill-in-the-blank. This increases the risk of memorizing the answer to the card rather than truly understanding the concept.\nWhat if we could use AI to help us understand a topic better?\nSocratesGPT Unless you\u0026rsquo;ve been living under a particularly forlorn boulder, you\u0026rsquo;ve heard about ChatGPT. You may not know that you can access GPT-3.5 as an API. The most advanced model available via OpenAI\u0026rsquo;s API is gpt-3.5-turbo. This space is moving fast. When I started this project, the most advanced model was text-davinci-003 which was 10x more expensive and somewhat slower. Edit: now GPT-4 is out.\nGPT (generative pre-trained transformer) is a type of \u0026ldquo;large language model\u0026rdquo; (LLM) (sorry about the acronyms). By using \u0026ldquo;prompt engineering\u0026rdquo;, you can have the model return a structured JSON output for a given prompt, which can then be rendered in a UI. This means the app\u0026rsquo;s \u0026ldquo;backend\u0026rdquo; can consist of a single prompt.\nI saw a great example of this at https://github.com/varunshenoy/GraphGPT. It shows an example of using one-shot prompting to teach GPT to give a JSON structured response. I was surprised to find that this style of prompting always gives back valid JSON, assuming you also set the model parameters appropriately.\nI created SocratesGPT to test the concept of using AI to generate questions about a given text. The Socratic method is a questioning style that encourages students to discover their beliefs and uncover hidden assumptions. However, SocratesGPT does not fully follow the Socratic style, as there is no real dialogue between student and teacher. The name is more aspirational than descriptive.\nIn my prompt, I ask the model to impersonate Socrates, and generate questions based on the given text. I also provide an example of the expected response in JSON format. The React front end parses the JSON and renders it. If you ask for another question, the app updates the prompt with the previous state of questions and options selected and pass it back to the model.\nCreating a traditional backend to power an app like this without the use of LLMs would be highly non-trivial.\n\u0026ldquo;Prompt Engineering\u0026rdquo; Prompt engineering is the process of designing effective prompts for large language models such as GPT. Effective prompts are more likely to elicit high-quality outputs. Garbage prompt in, garbage response from the LLM.\nI started with a fairly simple prompt:\nYou are impersonating a question generator using the socratic method. You will be given a prompt, and you must respond with a question about that prompt. The response must be a valid json object with the following fields: prompt, question, answer, and correct. Eventually I had to add the following lines to get a cleaner response:\nYou cannot ask the same question twice. Try to limit the number of words in the choices to 4. If a choice is selected, it should be marked as selected: true. If a choice is not selected, it should be marked as selected: false. I had the feeling of training an overly eager genie when phrasing my prompt. When you ask a genie to stop the trolley from hitting the pedestrian, the genie might find blowing up the trolley to be a perfectly reasonable solution. So you end up adding additional clauses: \u0026ldquo;err, also don\u0026rsquo;t blow it up!\u0026rdquo;.\nThis is followed by a one-shot training example, where I provide a single example of what I want the model to do. I provide a starting state with my initial data structure:\nExamples: current state: { \u0026#34;counter\u0026#34;: 1, \u0026#34;prompt\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;questions\u0026#34;: [{}] } prompt is the text the model should generate questions on. questions is an array of question objects.\nThen I show an example prompt, and the expected response from the model:\nprompt: The sky is blue. new state: { \u0026#34;counter\u0026#34;: 1, \u0026#34;prompt\u0026#34;: \u0026#34;The sky is blue.\u0026#34;, \u0026#34;questions\u0026#34;: [{ \u0026#34;question\u0026#34;: \u0026#34;What color is the sky?\u0026#34;, \u0026#34;choices\u0026#34;: [{ \u0026#34;text\u0026#34;: \u0026#34;blue\u0026#34;, \u0026#34;correct\u0026#34;: true, \u0026#34;selected\u0026#34;: false }, { \u0026#34;text\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;correct\u0026#34;: false, \u0026#34;selected\u0026#34;: false }, { \u0026#34;text\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;correct\u0026#34;: false, \u0026#34;selected\u0026#34;: false }, { \u0026#34;text\u0026#34;: \u0026#34;yellow\u0026#34;, \u0026#34;correct\u0026#34;: false, \u0026#34;selected\u0026#34;: false }] }] } Each question includes the generated question, along with an array of choices. The selected boolean is used in the front end to maintain the state of which options the user clicked, so these aren\u0026rsquo;t lost when a new prompt is generated.\nFinally we create a way for us to dynamically update the prompt:\ncurrent state: $state prompt: $prompt new state: In the front end, we inject the current state into $state and the prompt into $prompt:\nfetch(\u0026#34;prompts/data.prompt\u0026#34;) .then((response) =\u0026gt; response.text()) .then((text) =\u0026gt; text.replace(\u0026#34;$prompt\u0026#34;, prompt)) .then((text) =\u0026gt; text.replace(\u0026#34;$state\u0026#34;, JSON.stringify(state))) We have some control over the parameters of the model, such as the temperature, max tokens, and top p. I found that the model works best when the temperature is set to 0.3. Temperature controls the \u0026ldquo;creativity\u0026rdquo; of the model. A lower temperature means the model is more likely to generate correct, almost deterministic responses. A higher temperature means the model generally leads to creative responses. frequency_penalty sets a penalty for repeating words. presence_penalty sets a penalty for repeating n-grams. top_p sets the probability mass function cutoff.\nconst DEFAULT_PARAMS = { model: \u0026#34;gpt-3.5-turbo\u0026#34;, temperature: 0.3, max_tokens: 800, top_p: 1, frequency_penalty: 0, presence_penalty: 0, }; After the user clicks \u0026ldquo;Generate Question\u0026rdquo;, the value of $prompt is obtained from the prompt text area in the UI. The $state starts as a skeleton of the data structure provided in the training example. We call OpenAI\u0026rsquo;s new gpt-3.5-turbo chat completions API with data.prompt. The JSON response contained in data.choices[0].message.content is parsed to update the state and render the question in the UI.\nI found that the prompt in the new API needs to use single quotes instead of quotes when sent to the model, and then I have to replace the single quotes in the response with double quotes again to make it valid JSON. There\u0026rsquo;s probably a cleaner way to do this. I also feed the entire prompt as the role user, but some parts of it may be better suited to the system role.\nconst params = { ...DEFAULT_PARAMS, messages: [{ role: \u0026#34;user\u0026#34;, content: prompt }], }; ... const requestOptions = { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, Authorization: \u0026#34;Bearer \u0026#34; + String(apiKey || OPENAI_API_KEY), }, body: JSON.stringify(params), }; fetch(\u0026#34;https://api.openai.com/v1/chat/completions\u0026#34;, requestOptions) .then((response) =\u0026gt; response.json()) .then((data) =\u0026gt; { const text = data.choices[0].message.content; // replace \u0026#39; with \u0026#34; to make it valid JSON const new_state = JSON.parse(text.replace(/\u0026#39;/g, \u0026#39;\u0026#34;\u0026#39;)); setState(new_state); If the user generates another question, we pass in the $state which now includes the first question. This lets the model we know what it already asked.\nLimitations There are several limitations with the current implementation:\nWhen providing very short input text, the model may generate questions that are not grounded in the text. For example, if the input text is \u0026ldquo;The sky is blue\u0026rdquo;, the model may generate a question like \u0026ldquo;Why is the sky blue?\u0026rdquo; even though the reason is not provided in the text. This is related to the \u0026ldquo;grounding problem\u0026rdquo;, which is one of the major flaws of LLMs. Shorter input text provides less grounding, thus allowing for more hallucinations. Occasionally, the model seems to \u0026ldquo;undo\u0026rdquo; changes in state. For example, a question might get removed from state on the next run. It can take up to 20 seconds to receive a response from the API. The response time seems to increase with the size of the prompt. This can make it less engaging. Newer versions of the OpenAI API will likely have faster response times. Setting frequency_penalty and presense_penalty parameters to 1 seems to result in invalid JSON. This might be because they make the model less likely to generate characters like { multiple times, which is required for the JSON to be valid. Future There\u0026rsquo;s a few ways SocratesGPT could be improved. Users could be able to save questions, and later be quizzed on them using spaced repetition. Larger context windows would allow the model to create questions on entire books. Eventually, GPT could be \u0026ldquo;fine-tuned\u0026rdquo; to ask more effective questions. You might even be able to implement reinforcement learning from human feedback (RLHF). Students could rate the quality of questions, which is then fed back into the model.\nAs multi-modal models mature, the AI could even generate diagrams, such as an image of a section of the brain with an arrow pointing to the area that the user is asked to label. Finally, the grounding problem should be addressed to prevent the model from \u0026ldquo;hallucinating\u0026rdquo; questions that are not in the input text.\nThe \u0026ldquo;T\u0026rdquo; in GPT stands for transformer, which is currently the most powerful deep learning architecture for several tasks, including NLP. There will likely be better architectures in the future. As the cost of GPU compute decreases, larger models with many more parameters become possible. By building on improvements like these, we can create ever more advanced AI tutors. These tutors will be able to understand your learning goals and current understanding to create personalized curriculums that are just difficult enough to challenge and ensure long term retention.\nAdvancing AI can help close the gap that MOOCs currently have difficulty filling, and help to scale education. Increased education leads to more people with advanced degrees that can help us solve some of our most pressing challenges. These are still the early days of LLMs.\n","permalink":"https://tenzinwangdhen.com/posts/augmenting-human-intelligence-with-ai/","summary":"TLDR I created SocratesGPT to test the concept of using AI to generate questions about a given topic. Its goal you learn topics better by asking you questions about it. I also provide some technical details on the implementation.\nWhy? Over a year ago, I began using Anki, a spaced repetition flashcard app that helps me retain information over the long term by taking advantage of the Ebbinghaus forgetting curve. Memory is like a leaky bucket, and it was incredibly frustrating to realize I\u0026rsquo;d forgotten most of what I learned.","title":"Augmenting Human Intelligence With AI"}]