<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Nvidia - Barbarians at the Moat | Tenzin&#39;s Blog</title>
<meta name="keywords" content="business, ai, hardware">
<meta name="description" content="Nvidia&#39;s rise to dominance and the challenges ahead">
<meta name="author" content="Tenzin Wangdhen">
<link rel="canonical" href="https://tenzinwangdhen.com/posts/nvidia-barbarians-at-the-moat/">
<meta name="google-site-verification" content="XYZabc">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1443025edf561866ac87002e4fa1fcc308bee7d2cbae932ea8cd31d7383411f4.css" integrity="sha256-FEMCXt9WGGashwAuT6H8wwi&#43;59LLrpMuqM0x1zg0EfQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://tenzinwangdhen.com/%3Clink%20/%20abs%20url%3E">
<link rel="icon" type="image/png" sizes="16x16" href="https://tenzinwangdhen.com/%3Clink%20/%20abs%20url%3E">
<link rel="icon" type="image/png" sizes="32x32" href="https://tenzinwangdhen.com/%3Clink%20/%20abs%20url%3E">
<link rel="apple-touch-icon" href="https://tenzinwangdhen.com/%3Clink%20/%20abs%20url%3E">
<link rel="mask-icon" href="https://tenzinwangdhen.com/%3Clink%20/%20abs%20url%3E">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1LK2EC2CML"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-1LK2EC2CML', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Nvidia - Barbarians at the Moat" />
<meta property="og:description" content="Nvidia&#39;s rise to dominance and the challenges ahead" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tenzinwangdhen.com/posts/nvidia-barbarians-at-the-moat/" /><meta property="og:image" content="https://tenzinwangdhen.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-09T01:17:15-07:00" />
<meta property="article:modified_time" content="2024-08-09T01:17:15-07:00" /><meta property="og:site_name" content="Tenzin&#39;s Blog" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://tenzinwangdhen.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"/>

<meta name="twitter:title" content="Nvidia - Barbarians at the Moat"/>
<meta name="twitter:description" content="Nvidia&#39;s rise to dominance and the challenges ahead"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://tenzinwangdhen.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Nvidia - Barbarians at the Moat",
      "item": "https://tenzinwangdhen.com/posts/nvidia-barbarians-at-the-moat/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Nvidia - Barbarians at the Moat",
  "name": "Nvidia - Barbarians at the Moat",
  "description": "Nvidia's rise to dominance and the challenges ahead",
  "keywords": [
    "business", "ai", "hardware"
  ],
  "articleBody": "Nvidia is one of the largest companies in the world, frequently taking the top spot. It’s revenue is growing at an astonishing rate, with margins better than a lot of pure software businesses - something usually unheard of for hardware companies. All of this is on the back of a massive AI hype cycle. During a gold rush, you should sell picks and shovels. Nvidia is selling bulldozers. In this post, I will dive into the components of Nvidia’s competitive moat, its strengths and weaknesses, and the competitors trying to cross it.\nIn a capitalist system, profits are always competed away, unless you’ve managed to create a legal monopoly (i.e. power companies, Google). Nvidia does not have a monopoly, but they do have a near impenetrable moat.\nToday, consumer GPUs make up just a fraction of Nvidia’s revenue. The vast majority of it comes from their data center business. Very large companies with massive data centers like Tesla, Meta, and OpenAI (the “hyperscalers”) are in an arms race to acquire the currently scare resource that is Nvidia GPUs, which are, for now, basically the only game in town for AI training hardware. And because of that, Nvidia can charge exorbitant amounts for their GPUs. Nvidia’s margin of 71% is larger than most SaaS companies, something previously unheard of for hardware companies selling commodities.\nSource: https://www.investmentideas.io/p/nvidia-pivoting-towards-chiplets\nSo how did Nvidia get into this enviable position?\nMost of it comes down to the foresight of Nvidia’s founder Jensen Huang. He realized that GPUs could be used for scientific computing and started building CUDA even before there were real use cases. Through a stroke of good luck, the creators of AlexNet thought to use Nvidia GPUs and CUDA to train a model that won the ImageNet competition in 2012. This marked the beginning of the deep learning revolution. Deep learning is “embarassingly parallel” problem, and GPUs are perfectly suited to parallel processing.\nA Primer on GPUs A bit of an aside on CPUs vs GPUs (graphics processing units), and why GPUs are so much better for modern AI.\nTo help you develop a grossly simplified mental model, I will provide an analogy. Say you have to deliver a ton of coffee beans from Guatemala to Miami. You could use a jet (the CPU) which can carry one bag of beans (data) from the warehouse (memory) very quickly to and from Miami.\nOr you can use a cargo plane (a GPU), which can carry a ton of bags much more slowly. The jet is optimized to prioritize latency (or speed), while the cargo plane is optimized to prioritize cargo capacity (memory bandwidth).\nSmaller coffee shops that require different types of beans might benefit more from the jet since they need a small amount delivered quickly. This represents the general compute that a CPU is tasked with. Large coffee chains like Starbucks just need a consistent amount of the same beans in bulk. This represents the high bandwidth parallel processing required from the GPU.\nWhen training a model, you need to run a single operation, usually matrix multiplication, on a large amount of data. The GPU, with its memory bandwidth, is much better suited to this task than the CPU. The tradeoff is that each individual task is slower, but you can simply add more parallelism (i.e., cargo planes).\nGPUs, or graphics processing units, used to only be used for, well, processing graphics. Rendering graphics requires parallel processing and would be too slow to do on a CPU. Jensen’s insight was that this parallelism would be useful for tasks other than graphics processing, namely scientific computing. But in order for end users to be able to take advantage of the GPU for tasks other than gaming, they needed a programmable software interface on top of the GPU. That is where CUDA, or Compute Unified Device Architecture, comes in.\nCUDA Nvidia created CUDA before knowing whether there would even be a significant market for it. Their competitors, such as AMD, completely ignored this development. With AlexNet, CUDA found it’s “build it and they will come” moment. Deep learning needed to be done on GPUs, and Nvidia GPUs were the only usable ones because they have CUDA.\nAlmost every deep learning library (PyTorch, TensorFlow, Keras, etc.) is built on top of CUDA. There is an entire ecosystem of guides, blogs, StackOverflow posts that support CUDA users. AI researchers looking to train a model or experiment with new types of models favor Nvidia because they want an out of the box solution to working with the GPU without having to waste their time. Unsurprisingly, CUDA only works for Nvidia GPUs and is closed-source. CUDA has created a network effect for Nvidia GPUs, as the value of each GPU increases as the number of users increases. Any rival to Nvidia needs to be able to convince users than their offering is enticing enough to forego this massive ecosystem.\nCUDA is just one of several software products the company produces. One of the most exciting is Omniverse, which uses Nvidia hardware to create “world scale” simulations. Automakers for example are using this to create “digital twins” of their assembly lines, where they can perfect configurations in the digital realm before implementing them in reality, among other applications. The real value here is the ability to create synthetic data sets at scale. Quality data is one of the key scarce resources in developing AI models.\nCUDA is of course not how Nvidia makes the bulk of its money. Nvidia is first and foremost a hardware company. They have been building GPUs for over three decades, and have perfected the art.\nNvidia Hardware The current best Nvidia AI GPU is the H200. It has 141GB HBM memory with a total bandwidth of 4.8TB/s per GPU across six HBM3e stacks. HBM memory, which consists of three dimensional stacks of memory chips, represents the cutting edge in high bandwidth memory. In my earlier analogy, HBM memory would represent a much larger storage area in the cargo plane.\nTo put the 141GB of memory into perspective, I built an AI PC with a consumer grade RTX 4090 last year. It has 24GB of memory, and can only fit Llama with 7 billion parameters. The H200 can fit Llama with 70 billion parameters. It still would not fit Claude 3.5 which as 2 trillion parameters though, so you’d need to network multiple GPUs together.\nAt GTC 2024, Nvidia announced the B200 “Blackwell” GPU, and a GB200 “superchip”. The B200 has up to 20 petaflops of processing power and 192GB HBM memory. Training a 1.8 trillion parameter model (such as GPT 4) would only require 2,000 B200’s, whereas it would have taken 8,000 previous generation “Hopper” chips for the same task. All of this while consuming a fourth of the energy. Suggested retail price from Nvidia: $30,000 to $50,000 each. In comparison, AMD’s competing MI300X costs between $10,000 to $15,000. Interestingly, Nvidia is not increasing the price for the Blackwell class chips as much as expected.\nThese chips can also be networked together with a next-gen NVLink switch, which can connect up to 576 GPUs with 1.8TB/s bidirectional bandwidth.\nNow that I have sung Nvidia’s praises, it’s time to explore the threats to their business\nThe Chiplet Threat Nvidia GPUs have a monolithic architecture. They often feature a single large chip. This means that if there is any issue with a chip during manufacturing, the whole chip needs to be discarded. AMD is working on chiplets for GPUs, which are several smaller chips that are stitched together to make one big chip. They already do this for their CPUs. If a smaller chip has an issue, you can replace just that one chip, thereby increasing yields. This means AMD could make GPUs on par with Nvidia, but at lower cost.\nLarge chips are also starting to run into the lithographic reticle limit, whereby producing cutting edge chips at nanometer scale becomes exponentially more expensive and eventually physically impossible. Chiplets on the other hand are still far away from this limit. AMD has been making chiplets for a while already and has a bit of a process moat, since getting chiplet production right requires a lot of trial and error. Nvidia only recently started breaking up the monolithic chip in the Blackwell version, which is just two big chips stitched together. If Nvidia continues down the path of making monolithic chips, they risk disruption by chiplets.\nInference Another opening for competitors is the difference in requirements for training AI models vs “inference”. In simple terms, training a model is the actual creation of the AI model. GPT is a trained AI model. Inference is the process of getting outputs from the trained model. When you ask GPT a question, that is inference. Training requires much more compute power than inference, while inference requires much lower latency. Nvidia GPUs are currently the best available for training, but are already outperformed on inference by competitors, such as Groq.\nIf the need for inference scales more than the need for training, AI infrastructure spend could start to flow away from Nvidia unless they can create a competitive inference solution. Nvidia does already have open source frameworks focused on inference like TensorRT and is touting the inference performance of their Blackwell chips, so they likely realize this threat.\nThe Open Source Threat The crown jewel of Nvidia’s competitive moat, CUDA, is also coming under attack. As discussed earlier, CUDA is what currently makes Nvidia the default choice for AI researchers and model creators. It is part of what justifies Nvidia’s exorbitant margins. Nvidia’s competitors are finally starting to realize the leverage that can be gained from offering a library like CUDA. AMD’s CUDA alternative is ROCm. Unlike Nvidia, they have open sourced ROCm. If CUDA remains closed-source, the contributions of the open source community could eventually make ROCm a more attractive platform.\nVendor lock-in is when you are forced to stick with one vendor for a particular service. Most software company operators (and probably most business owners in general) would agree that vendor lock-in is bad, especially for a core component of your business. If you’re locked in, the vendor can charge a right arm for crappy service and you’d just have to take it. Currently, most companies in the AI space are locked in to Nvidia GPUs. They therefore have a huge incentive to either develop or fund alternatives.\nA Bubble? There is no question that we are in the middle of a massive AI bubble currently. AGI, a technology that, if manifested, could be the last technology we as a race would need to create, seems to be just around the corner. This has sparked a trillion dollar arms race among the largest companies in the world. For that spend, some would argue that we should have gotten more than a some chatbots and image generators. Sequoia’s David Cahn calls this a $600 billion dollar hole. Almost all of that money has flowed to Nvidia. LLMs using the transformer architecture need exponentially more parameters for near linear performance increase. If real enterprise value isn’t created relatively soon, the bubble will burst, resulting in a precipitous drop in revenue for Nvidia.\nAn analogous historical parallel to Nvidia is Cisco Systems. During the internet bubble, everyone was clamoring for Cisco networking hardware. This sent their stock surging over 1000x over a decade. However, the stock lost 88% of its value and has yet to reach it’s peak again over twenty years later.\nTLDR Nvidia is the big winner of the current AI hype wave. They have a seemingly insurmountable moat that is comprised of cutting edge hardware and the dominant software interface for it. The largest companies in the world are stocking up on this hardware at exorbitant prices to remain on the cutting edge. There are, however, significant threats to Nvidia’s continued dominance. Their monolithic chip strategy might hit a scaling wall, leaving them scrambling to catch up to chiplets. The demand for inference might outweigh that of training, requiring them to refactor much of their development pipeline. CUDA might be superseded by open source alternatives like ROCm, diminishing the need to stay on Nvidia GPUs - a trend that will likely have support from Nvidia’s largest customers. Finally, the current AI bubble could burst, resulting in significantly reduced spend on GPUs for AI use cases.\n",
  "wordCount" : "2065",
  "inLanguage": "en",
  "datePublished": "2024-08-09T01:17:15-07:00",
  "dateModified": "2024-08-09T01:17:15-07:00",
  "author":{
    "@type": "Person",
    "name": "Tenzin Wangdhen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tenzinwangdhen.com/posts/nvidia-barbarians-at-the-moat/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Tenzin's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tenzinwangdhen.com/%3Clink%20/%20abs%20url%3E"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://tenzinwangdhen.com" accesskey="h" title="Tenzin&#39;s Blog (Alt + H)">
                <img src="https://tenzinwangdhen.com/apple-touch-icon.png" alt="" aria-label="logo"
                    height="35">Tenzin&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://tenzinwangdhen.com/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://tenzinwangdhen.com/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://tenzinwangdhen.com/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://tenzinwangdhen.com">Home</a>&nbsp;»&nbsp;<a href="https://tenzinwangdhen.com/posts/">Posts</a></div>
    <h1 class="post-title">
      Nvidia - Barbarians at the Moat
    </h1>
    <div class="post-description">
      Nvidia&#39;s rise to dominance and the challenges ahead
    </div>
    <div class="post-meta"><span title='2024-08-09 01:17:15 -0700 -0700'>August 9, 2024</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;2065 words&nbsp;·&nbsp;Tenzin Wangdhen&nbsp;|&nbsp;<a href="https://github.com/sinzin91/tesseract-blog/blob/master/content/posts/nvidia-barbarians-at-the-moat.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#a-primer-on-gpus">A Primer on GPUs</a></li>
    <li><a href="#cuda">CUDA</a></li>
    <li><a href="#nvidia-hardware">Nvidia Hardware</a></li>
    <li><a href="#the-chiplet-threat">The Chiplet Threat</a></li>
    <li><a href="#inference">Inference</a></li>
    <li><a href="#the-open-source-threat">The Open Source Threat</a></li>
    <li><a href="#a-bubble">A Bubble?</a></li>
    <li><a href="#tldr">TLDR</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>Nvidia is one of the largest companies in the world, frequently taking the top spot. It&rsquo;s revenue is growing at an astonishing rate, with margins better than a lot of pure software businesses - something usually unheard of for hardware companies. All of this is on the back of a massive AI hype cycle. During a gold rush, you should sell picks and shovels. Nvidia is selling bulldozers. In this post, I will dive into the components of Nvidia&rsquo;s competitive moat, its strengths and weaknesses, and the competitors trying to cross it.</p>
<p>In a capitalist system, profits are always competed away, unless you&rsquo;ve managed to create a legal monopoly (i.e. power companies, Google). Nvidia does not have a monopoly, but they do have a near impenetrable moat.</p>
<p>Today, consumer GPUs make up just a fraction of Nvidia&rsquo;s revenue. The vast majority of it comes from their data center business. Very large companies with massive data centers like Tesla, Meta, and OpenAI (the &ldquo;hyperscalers&rdquo;) are in an arms race to acquire the currently scare resource that is Nvidia GPUs, which are, for now, basically the only game in town for AI training hardware. And because of that, Nvidia can charge exorbitant amounts for their GPUs. Nvidia&rsquo;s margin of 71% is larger than most SaaS companies, something previously unheard of for hardware companies selling commodities.</p>
<p><img loading="lazy" src="/images/nvidia-revenue.png" alt="Nvidia Revenue"  />
</p>
<blockquote>
<p>Source: <a href="https://www.investmentideas.io/p/nvidia-pivoting-towards-chiplets">https://www.investmentideas.io/p/nvidia-pivoting-towards-chiplets</a></p>
</blockquote>
<p>So how did Nvidia get into this enviable position?</p>
<p>Most of it comes down to the foresight of Nvidia&rsquo;s founder Jensen Huang. He realized that GPUs could be used for scientific computing and started building CUDA even before there were real use cases. Through a stroke of good luck, the creators of AlexNet thought to use Nvidia GPUs and CUDA to train a model that won the ImageNet competition in 2012. This marked the beginning of the deep learning revolution. Deep learning is &ldquo;embarassingly parallel&rdquo; problem, and GPUs are perfectly suited to parallel processing.</p>
<h2 id="a-primer-on-gpus">A Primer on GPUs<a hidden class="anchor" aria-hidden="true" href="#a-primer-on-gpus">#</a></h2>
<p>A bit of an aside on CPUs vs GPUs (graphics processing units), and why GPUs are so much better for modern AI.</p>
<p>To help you develop a grossly simplified mental model, I will provide an analogy. Say you have to deliver a ton of coffee beans from Guatemala to Miami. You could use a jet (the CPU) which can carry one bag of beans (data) from the warehouse (memory) very quickly to and from Miami.</p>
<p>Or you can use a cargo plane (a GPU), which can carry a ton of bags much more slowly. The jet is optimized to prioritize latency (or speed), while the cargo plane is optimized to prioritize cargo capacity (memory bandwidth).</p>
<p>Smaller coffee shops that require different types of beans might benefit more from the jet since they need a small amount delivered quickly. This represents the general compute that a CPU is tasked with. Large coffee chains like Starbucks just need a consistent amount of the same beans in bulk. This represents the high bandwidth parallel processing required from the GPU.</p>
<p>When training a model, you need to run a single operation, usually matrix multiplication, on a large amount of data. The GPU, with its memory bandwidth, is much better suited to this task than the CPU. The tradeoff is that each individual task is slower, but you can simply add more parallelism (i.e., cargo planes).</p>
<p>GPUs, or graphics processing units, used to only be used for, well, processing graphics. Rendering graphics requires parallel processing and would be too slow to do on a CPU. Jensen&rsquo;s insight was that this parallelism would be useful for tasks other than graphics processing, namely scientific computing. But in order for end users to be able to take advantage of the GPU for tasks other than gaming, they needed a programmable software interface on top of the GPU. That is where CUDA, or Compute Unified Device Architecture, comes in.</p>
<h2 id="cuda">CUDA<a hidden class="anchor" aria-hidden="true" href="#cuda">#</a></h2>
<p>Nvidia created CUDA before knowing whether there would even be a significant market for it. Their competitors, such as AMD, completely ignored this development. With AlexNet, CUDA found it&rsquo;s &ldquo;build it and they will come&rdquo; moment. Deep learning needed to be done on GPUs, and Nvidia GPUs were the only usable ones because they have CUDA.</p>
<p>Almost every deep learning library (PyTorch, TensorFlow, Keras, etc.) is built on top of CUDA. There is an entire ecosystem of guides, blogs, StackOverflow posts that support CUDA users. AI researchers looking to train a model or experiment with new types of models favor Nvidia because they want an out of the box solution to working with the GPU without having to waste their time. Unsurprisingly, CUDA only works for Nvidia GPUs and is closed-source. CUDA has created a <a href="https://www.investmentideas.io/p/nvidia-subject-to-disruption">network effect</a> for Nvidia GPUs, as the value of each GPU increases as the number of users increases. Any rival to Nvidia needs to be able to convince users than their offering is enticing enough to forego this massive ecosystem.</p>
<p>CUDA is just one of <a href="https://www.nvidia.com/en-us/software/">several</a> software products the company produces. One of the most exciting is Omniverse, which uses Nvidia hardware to create &ldquo;world scale&rdquo; simulations. Automakers for example are using this to create &ldquo;digital twins&rdquo; of their assembly lines, where they can perfect configurations in the digital realm before implementing them in reality, among other applications. The real value here is the ability to create synthetic data sets at scale. Quality data is one of the key scarce resources in developing AI models.</p>
<p>CUDA is of course not how Nvidia makes the bulk of its money. Nvidia is first and foremost a hardware company. They have been building GPUs for over three decades, and have perfected the art.</p>
<h2 id="nvidia-hardware">Nvidia Hardware<a hidden class="anchor" aria-hidden="true" href="#nvidia-hardware">#</a></h2>
<p>The current best Nvidia AI GPU is the <a href="https://www.tomshardware.com/news/nvidia-h200-gpu-announced">H200</a>. It has 141GB HBM memory with a total bandwidth of 4.8TB/s per GPU across six HBM3e stacks. HBM memory, which consists of three dimensional stacks of memory chips, represents the cutting edge in high bandwidth memory. In my earlier analogy, HBM memory would represent a much larger storage area in the cargo plane.</p>
<p>To put the 141GB of memory into perspective, I <a href="https://tenzinwangdhen.com/posts/ml-pc-build-log/">built an AI PC</a> with a consumer grade RTX 4090 last year. It has 24GB of memory, and can only fit Llama with 7 billion parameters. The H200 can fit Llama with 70 billion parameters. It still would not fit Claude 3.5 which as 2 trillion parameters though, so you&rsquo;d need to network multiple GPUs together.</p>
<p>At GTC 2024, Nvidia <a href="https://www.reuters.com/technology/nvidia-ai-developer-conference-kicks-off-with-new-chips-focus-2024-03-18/">announced</a> the B200 &ldquo;Blackwell&rdquo; GPU, and a GB200 &ldquo;superchip&rdquo;. The B200 has up to 20 petaflops of processing power and 192GB HBM memory. Training a 1.8 trillion parameter model (such as GPT 4) would only require 2,000 B200&rsquo;s, whereas it would have taken 8,000 previous generation &ldquo;Hopper&rdquo; chips for the same task. All of this while consuming a fourth of the energy. Suggested retail price from Nvidia: $30,000 to $50,000 each. In comparison, AMD&rsquo;s competing MI300X costs between $10,000 to $15,000. Interestingly, Nvidia is not increasing the price for the Blackwell class chips as much as expected.</p>
<p>These chips can also be networked together with a next-gen NVLink switch, which can connect up to 576 GPUs with 1.8TB/s bidirectional bandwidth.</p>
<p>Now that I have sung Nvidia&rsquo;s praises, it&rsquo;s time to explore the threats to their business</p>
<h2 id="the-chiplet-threat">The Chiplet Threat<a hidden class="anchor" aria-hidden="true" href="#the-chiplet-threat">#</a></h2>
<p>Nvidia GPUs have a <em>monolithic</em> architecture. They often feature a single large chip. This means that if there is any issue with a chip during manufacturing, the whole chip needs to be discarded. AMD is working on <a href="https://www.pcgamer.com/amds-new-chiplet-gpu-patent-could-finally-do-for-graphics-cards-what-ryzen-did-for-its-cpus/">chiplets</a> for GPUs, which are several smaller chips that are stitched together to make one big chip. They already do this for their CPUs. If a smaller chip has an issue, you can replace just that one chip, thereby increasing yields. This means AMD could make GPUs on par with Nvidia, but at lower cost.</p>
<p>Large chips are also starting to run into the <a href="https://en.wikichip.org/wiki/mask#:~:text=Reticle%20limit%5Bedit%5D,use%20of%20anamorphic%20lens%20array.">lithographic reticle limit</a>, whereby producing cutting edge chips at nanometer scale becomes exponentially more expensive and eventually physically impossible. Chiplets on the other hand are still far away from this limit. AMD has been making chiplets for a while already and has a bit of a process moat, since getting chiplet production right requires a lot of trial and error. Nvidia only recently started breaking up the monolithic chip in the Blackwell version, which is just two big chips stitched together. If Nvidia continues down the path of making monolithic chips, they risk <a href="https://www.investmentideas.io/p/nvidia-pivoting-towards-chiplets">disruption by chiplets</a>.</p>
<h2 id="inference">Inference<a hidden class="anchor" aria-hidden="true" href="#inference">#</a></h2>
<p>Another opening for competitors is the difference in requirements for training AI models vs &ldquo;inference&rdquo;. In simple terms, training a model is the actual creation of the AI model. GPT is a trained AI model. Inference is the process of getting outputs from the trained model. When you ask GPT a question, that is inference. Training requires much more compute power than inference, while inference requires much lower latency. Nvidia GPUs are currently the best available for training, but are already outperformed on inference by competitors, such as <a href="https://www.kavout.com/blog/groq-ai-real-time-inference-emerges-as-the-challenger-to-nvda-openai-and-google/#">Groq</a>.</p>
<p>If the need for inference scales more than the need for training, AI infrastructure spend could start to flow away from Nvidia unless they can create a competitive inference solution. Nvidia does already have open source frameworks focused on inference like <a href="https://developer.nvidia.com/tensorrt">TensorRT</a> and is touting the inference performance of their Blackwell chips, so they likely realize this threat.</p>
<h2 id="the-open-source-threat">The Open Source Threat<a hidden class="anchor" aria-hidden="true" href="#the-open-source-threat">#</a></h2>
<p>The crown jewel of Nvidia&rsquo;s competitive moat, CUDA, is also coming under attack. As discussed earlier, CUDA is what currently makes Nvidia the default choice for AI researchers and model creators. It is part of what justifies Nvidia&rsquo;s exorbitant margins. Nvidia&rsquo;s competitors are finally starting to realize the leverage that can be gained from offering a library like CUDA. AMD&rsquo;s CUDA alternative is ROCm. Unlike Nvidia, they have open sourced ROCm. If CUDA remains closed-source, the contributions of the open source community could eventually make ROCm a more attractive platform.</p>
<p>Vendor lock-in is when you are forced to stick with one vendor for a particular service. Most software company operators (and probably most business owners in general) would agree that vendor lock-in is bad, especially for a core component of your business. If you&rsquo;re locked in, the vendor can charge a right arm for crappy service and you&rsquo;d just have to take it. Currently, most companies in the AI space are locked in to Nvidia GPUs. They therefore have a huge incentive to either develop or fund alternatives.</p>
<h2 id="a-bubble">A Bubble?<a hidden class="anchor" aria-hidden="true" href="#a-bubble">#</a></h2>
<p>There is no question that we are in the middle of a massive AI bubble currently. AGI, a technology that, if manifested, could be the last technology we as a race would need to create, seems to be just around the corner. This has sparked a trillion dollar arms race among the largest companies in the world. For that spend, some would argue that we should have gotten more than a some chatbots and image generators. Sequoia&rsquo;s David Cahn calls this a <a href="https://www.sequoiacap.com/article/ais-600b-question/">$600 billion dollar hole</a>. Almost all of that money has flowed to Nvidia. LLMs using the transformer architecture need exponentially more parameters for near linear performance increase. If real enterprise value isn&rsquo;t created relatively soon, the bubble will burst, resulting in a precipitous drop in revenue for Nvidia.</p>
<p>An analogous historical parallel to Nvidia is Cisco Systems. During the internet bubble, everyone was clamoring for Cisco networking hardware. This sent their stock surging over 1000x over a decade. However, the stock lost 88% of its value and has yet to reach it&rsquo;s peak again over twenty years later.</p>
<h2 id="tldr">TLDR<a hidden class="anchor" aria-hidden="true" href="#tldr">#</a></h2>
<p>Nvidia is the big winner of the current AI hype wave. They have a seemingly insurmountable moat that is comprised of cutting edge hardware and the dominant software interface for it. The largest companies in the world are stocking up on this hardware at exorbitant prices to remain on the cutting edge. There are, however, significant threats to Nvidia&rsquo;s continued dominance. Their monolithic chip strategy might hit a scaling wall, leaving them scrambling to catch up to chiplets. The demand for inference might outweigh that of training, requiring them to refactor much of their development pipeline. CUDA might be superseded by open source alternatives like ROCm, diminishing the need to stay on Nvidia GPUs - a trend that will likely have support from Nvidia&rsquo;s largest customers. Finally, the current AI bubble could burst, resulting in significantly reduced spend on GPUs for AI use cases.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://tenzinwangdhen.com/tags/business/">business</a></li>
      <li><a href="https://tenzinwangdhen.com/tags/ai/">ai</a></li>
      <li><a href="https://tenzinwangdhen.com/tags/hardware/">hardware</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://tenzinwangdhen.com/posts/catastrophic-failure-complex-systems/">
    <span class="title">« Prev</span>
    <br>
    <span>Catastrophic Failure in Complex Systems</span>
  </a>
  <a class="next" href="https://tenzinwangdhen.com/posts/moonwalking-with-einstein/">
    <span class="title">Next »</span>
    <br>
    <span>Book Review - Moonwalking With Einstein</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on x"
            href="https://x.com/intent/tweet/?text=Nvidia%20-%20Barbarians%20at%20the%20Moat&amp;url=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f&amp;hashtags=business%2cai%2chardware">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f&amp;title=Nvidia%20-%20Barbarians%20at%20the%20Moat&amp;summary=Nvidia%20-%20Barbarians%20at%20the%20Moat&amp;source=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f&title=Nvidia%20-%20Barbarians%20at%20the%20Moat">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on whatsapp"
            href="https://api.whatsapp.com/send?text=Nvidia%20-%20Barbarians%20at%20the%20Moat%20-%20https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on telegram"
            href="https://telegram.me/share/url?text=Nvidia%20-%20Barbarians%20at%20the%20Moat&amp;url=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Nvidia - Barbarians at the Moat on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Nvidia%20-%20Barbarians%20at%20the%20Moat&u=https%3a%2f%2ftenzinwangdhen.com%2fposts%2fnvidia-barbarians-at-the-moat%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://tenzinwangdhen.com">Tenzin&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
